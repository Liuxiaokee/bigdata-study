[INFO  2018-03-08 10:51:54][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 10:51:56][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 10:51:56][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:21)
[INFO  2018-03-08 10:51:57][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 10:51:57][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 10:51:57][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 10:51:59][main] Logging$class:58 Successfully started service 'sparkDriver' on port 62518.
[INFO  2018-03-08 10:51:59][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 10:51:59][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 10:52:00][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:62541]
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 62541.
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-e92e7929-95d2-44de-8d7c-efe71caafa1a
[INFO  2018-03-08 10:52:00][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 10:52:00][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 10:52:00][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 10:52:00][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62552.
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Server created on 62552
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 10:52:01][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:62552 with 2.4 GB RAM, BlockManagerId(driver, localhost, 62552)
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 10:52:01][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:36
[INFO  2018-03-08 10:52:01][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOfJavaOps.java:36) with 2 output partitions
[INFO  2018-03-08 10:52:01][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOfJavaOps.java:36)
[INFO  2018-03-08 10:52:01][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 10:52:01][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 10:52:01][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at map at TransFomationOfJavaOps.java:30), which has no missing parents
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 2.3 KB)
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1444.0 B, free 3.7 KB)
[INFO  2018-03-08 10:52:02][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:62552 (size: 1444.0 B, free: 2.4 GB)
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at TransFomationOfJavaOps.java:30)
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 10:52:02][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2150 bytes)
[INFO  2018-03-08 10:52:02][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2160 bytes)
[INFO  2018-03-08 10:52:02][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 10:52:02][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 10:52:02][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 10:52:02][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 10:52:02][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 69 ms on localhost (1/2)
[INFO  2018-03-08 10:52:02][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 109 ms on localhost (2/2)
[INFO  2018-03-08 10:52:02][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOfJavaOps.java:36) finished in 0.123 s
[INFO  2018-03-08 10:52:02][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 10:52:02][main] Logging$class:58 Job 0 finished: foreach at TransFomationOfJavaOps.java:36, took 0.470230 s
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 10:52:02][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 10:52:02][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 10:52:02][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 10:52:02][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 10:52:02][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 10:52:02][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 10:52:02][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 10:52:02][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 10:52:02][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 10:52:02][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 10:52:02][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 10:52:02][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-c5e824bb-0b32-41b3-ad27-e19cbb161a93
[INFO  2018-03-08 10:59:14][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 10:59:15][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 10:59:15][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:13)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 10:59:15][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 10:59:15][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 10:59:15][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 10:59:17][main] Logging$class:58 Successfully started service 'sparkDriver' on port 50107.
[INFO  2018-03-08 10:59:18][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 10:59:18][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 10:59:18][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:50120]
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 50120.
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-9bb41306-caae-4a4b-95f6-08240f25ca2c
[INFO  2018-03-08 10:59:18][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 10:59:18][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 10:59:18][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50139.
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Server created on 50139
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 10:59:18][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:50139 with 2.4 GB RAM, BlockManagerId(driver, localhost, 50139)
[INFO  2018-03-08 10:59:18][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 10:59:19][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:23
[INFO  2018-03-08 10:59:19][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:23) with 2 output partitions
[INFO  2018-03-08 10:59:19][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOps.scala:23)
[INFO  2018-03-08 10:59:19][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 10:59:19][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 10:59:19][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at map at TransFomationOps.scala:22), which has no missing parents
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 1936.0 B, free 1936.0 B)
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1244.0 B, free 3.1 KB)
[INFO  2018-03-08 10:59:20][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:50139 (size: 1244.0 B, free: 2.4 GB)
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at TransFomationOps.scala:22)
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 10:59:20][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2030 bytes)
[INFO  2018-03-08 10:59:20][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2034 bytes)
[INFO  2018-03-08 10:59:20][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 10:59:20][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 10:59:20][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 10:59:20][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 10:59:20][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 116 ms on localhost (1/2)
[INFO  2018-03-08 10:59:20][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 286 ms on localhost (2/2)
[INFO  2018-03-08 10:59:20][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOps.scala:23) finished in 0.317 s
[INFO  2018-03-08 10:59:20][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 10:59:20][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:23, took 0.763072 s
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 10:59:20][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 10:59:20][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 10:59:20][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 10:59:20][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 10:59:20][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 10:59:20][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 10:59:20][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 10:59:20][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 10:59:20][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 10:59:20][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 10:59:20][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 10:59:20][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-5650aa91-d15e-43c0-b82a-0d9784e661a7
[INFO  2018-03-08 11:07:59][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 11:08:00][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 11:08:00][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:21)
[INFO  2018-03-08 11:08:01][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 11:08:01][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 11:08:01][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 11:08:02][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54710.
[INFO  2018-03-08 11:08:02][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 11:08:03][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 11:08:03][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54731]
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54731.
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-04a471a1-a16e-40b7-bec2-acc8dbc835e0
[INFO  2018-03-08 11:08:03][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 11:08:03][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 11:08:03][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54750.
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Server created on 54750
[INFO  2018-03-08 11:08:03][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 11:08:04][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:54750 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54750)
[INFO  2018-03-08 11:08:04][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 11:08:04][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:57
[INFO  2018-03-08 11:08:04][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOfJavaOps.java:57) with 2 output partitions
[INFO  2018-03-08 11:08:04][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOfJavaOps.java:57)
[INFO  2018-03-08 11:08:04][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 11:08:04][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 11:08:04][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at filter at TransFomationOfJavaOps.java:51), which has no missing parents
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 2.3 KB)
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1425.0 B, free 3.7 KB)
[INFO  2018-03-08 11:08:05][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54750 (size: 1425.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at filter at TransFomationOfJavaOps.java:51)
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 11:08:05][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2150 bytes)
[INFO  2018-03-08 11:08:05][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2160 bytes)
[INFO  2018-03-08 11:08:05][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 11:08:05][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 11:08:05][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 11:08:05][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 11:08:05][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 68 ms on localhost (1/2)
[INFO  2018-03-08 11:08:05][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 101 ms on localhost (2/2)
[INFO  2018-03-08 11:08:05][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOfJavaOps.java:57) finished in 0.137 s
[INFO  2018-03-08 11:08:05][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:08:05][main] Logging$class:58 Job 0 finished: foreach at TransFomationOfJavaOps.java:57, took 0.469128 s
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 11:08:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 11:08:05][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 11:08:05][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 11:08:05][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 11:08:05][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 11:08:05][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 11:08:05][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 11:08:05][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 11:08:05][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 11:08:05][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 11:08:05][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 11:08:05][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-2efc2bee-1eeb-4a93-9f5c-efe28ea62131
[INFO  2018-03-08 11:10:22][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 11:10:23][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 11:10:24][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:13)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 11:10:24][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 11:10:24][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 11:10:24][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 11:10:25][main] Logging$class:58 Successfully started service 'sparkDriver' on port 56214.
[INFO  2018-03-08 11:10:26][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 11:10:26][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 11:10:26][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:56227]
[INFO  2018-03-08 11:10:26][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 56227.
[INFO  2018-03-08 11:10:26][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 11:10:26][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 11:10:26][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-cec8b313-ef71-4dc4-8518-0d219b8f4582
[INFO  2018-03-08 11:10:26][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 11:10:26][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 11:10:27][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 11:10:27][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56238.
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Server created on 56238
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 11:10:27][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:56238 with 2.4 GB RAM, BlockManagerId(driver, localhost, 56238)
[INFO  2018-03-08 11:10:27][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 11:10:28][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:31
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:31) with 2 output partitions
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOps.scala:31)
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at filter at TransFomationOps.scala:30), which has no missing parents
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 1936.0 B, free 1936.0 B)
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1238.0 B, free 3.1 KB)
[INFO  2018-03-08 11:10:28][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:56238 (size: 1238.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at filter at TransFomationOps.scala:30)
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 11:10:28][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2030 bytes)
[INFO  2018-03-08 11:10:28][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2034 bytes)
[INFO  2018-03-08 11:10:28][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 11:10:28][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 11:10:28][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 11:10:28][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 11:10:28][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 89 ms on localhost (1/2)
[INFO  2018-03-08 11:10:28][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 55 ms on localhost (2/2)
[INFO  2018-03-08 11:10:28][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:10:28][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOps.scala:31) finished in 0.111 s
[INFO  2018-03-08 11:10:28][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:31, took 0.383085 s
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 11:10:28][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 11:10:28][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 11:10:28][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 11:10:28][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 11:10:28][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 11:10:28][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 11:10:28][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 11:10:28][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 11:10:28][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 11:10:28][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 11:10:28][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 11:10:28][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-fe2c9d45-f7d8-43a1-9b22-5052fc3f6a55
[INFO  2018-03-08 11:27:45][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 11:27:46][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 11:27:46][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:22)
[INFO  2018-03-08 11:27:46][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 11:27:46][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 11:27:46][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 11:27:48][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55787.
[INFO  2018-03-08 11:27:48][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 11:27:48][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 11:27:49][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55803]
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55803.
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-bbc3882b-1216-4e38-beef-9908d656fec4
[INFO  2018-03-08 11:27:49][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 11:27:49][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 11:27:49][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55823.
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Server created on 55823
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 11:27:49][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:55823 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55823)
[INFO  2018-03-08 11:27:49][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 11:27:50][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:81
[INFO  2018-03-08 11:27:50][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOfJavaOps.java:81) with 2 output partitions
[INFO  2018-03-08 11:27:50][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOfJavaOps.java:81)
[INFO  2018-03-08 11:27:50][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 11:27:50][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 11:27:50][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at flatMap at TransFomationOfJavaOps.java:74), which has no missing parents
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.3 KB, free 2.3 KB)
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1436.0 B, free 3.7 KB)
[INFO  2018-03-08 11:27:51][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:55823 (size: 1436.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at flatMap at TransFomationOfJavaOps.java:74)
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 11:27:51][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2103 bytes)
[INFO  2018-03-08 11:27:51][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2122 bytes)
[INFO  2018-03-08 11:27:51][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 11:27:51][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 11:27:51][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 11:27:51][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 11:27:51][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 62 ms on localhost (1/2)
[INFO  2018-03-08 11:27:51][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 94 ms on localhost (2/2)
[INFO  2018-03-08 11:27:51][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:27:51][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOfJavaOps.java:81) finished in 0.122 s
[INFO  2018-03-08 11:27:51][main] Logging$class:58 Job 0 finished: foreach at TransFomationOfJavaOps.java:81, took 0.393432 s
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 11:27:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 11:27:51][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 11:27:51][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 11:27:51][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 11:27:51][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 11:27:51][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 11:27:51][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 11:27:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 11:27:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 11:27:51][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 11:27:51][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 11:27:51][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-0e75a611-69c3-4d48-a309-a428ce418630
[INFO  2018-03-08 11:34:26][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 11:34:28][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 11:34:28][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:22)
[INFO  2018-03-08 11:34:28][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 11:34:28][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 11:34:28][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 11:34:29][main] Logging$class:58 Successfully started service 'sparkDriver' on port 59523.
[INFO  2018-03-08 11:34:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 11:34:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 11:34:30][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:59544]
[INFO  2018-03-08 11:34:30][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 59544.
[INFO  2018-03-08 11:34:30][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 11:34:30][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 11:34:30][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-4eebe384-631d-4119-ad94-806eb4bf34cd
[INFO  2018-03-08 11:34:30][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 11:34:30][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 11:34:31][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 11:34:31][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59555.
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Server created on 59555
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 11:34:31][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:59555 with 2.4 GB RAM, BlockManagerId(driver, localhost, 59555)
[INFO  2018-03-08 11:34:31][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 11:34:32][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:95
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at TransFomationOfJavaOps.java:81)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOfJavaOps.java:95) with 2 output partitions
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:95)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at TransFomationOfJavaOps.java:81), which has no missing parents
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.5 KB, free 3.5 KB)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 2047.0 B, free 5.5 KB)
[INFO  2018-03-08 11:34:32][dispatcher-event-loop-3] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:59555 (size: 2047.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at TransFomationOfJavaOps.java:81)
[INFO  2018-03-08 11:34:32][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 11:34:32][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 11:34:32][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 11:34:32][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 11:34:32][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 11:34:33][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 11:34:33][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 11:34:33][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 154 ms on localhost (1/2)
[INFO  2018-03-08 11:34:33][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on localhost (2/2)
[INFO  2018-03-08 11:34:33][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at TransFomationOfJavaOps.java:81) finished in 0.213 s
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at reduceByKey at TransFomationOfJavaOps.java:88), which has no missing parents
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 8.5 KB)
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 1801.0 B, free 10.2 KB)
[INFO  2018-03-08 11:34:33][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:59555 (size: 1801.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at reduceByKey at TransFomationOfJavaOps.java:88)
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 11:34:33][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 11:34:33][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 11:34:33][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 11:34:33][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 11:34:33][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 11:34:33][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 11:34:33][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 11:34:33][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 11:34:33][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 11:34:33][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 11:34:33][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 73 ms on localhost (1/2)
[INFO  2018-03-08 11:34:33][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 69 ms on localhost (2/2)
[INFO  2018-03-08 11:34:33][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:34:33][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:95) finished in 0.074 s
[INFO  2018-03-08 11:34:33][main] Logging$class:58 Job 0 finished: foreach at TransFomationOfJavaOps.java:95, took 0.761220 s
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 11:34:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 11:34:33][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 11:34:33][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 11:34:33][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 11:34:33][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 11:34:33][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 11:34:33][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 11:34:33][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 11:34:33][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 11:34:33][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 11:34:33][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 11:34:33][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-bf413a3b-265b-4dde-b9c9-e1beb44335cd
[INFO  2018-03-08 11:39:02][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 11:39:03][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 11:39:03][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 11:39:03][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 11:39:03][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 11:39:03][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 11:39:04][main] Logging$class:58 Successfully started service 'sparkDriver' on port 61895.
[INFO  2018-03-08 11:39:05][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 11:39:05][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 11:39:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:61916]
[INFO  2018-03-08 11:39:05][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 61916.
[INFO  2018-03-08 11:39:05][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 11:39:05][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 11:39:05][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-0566cb91-a582-46fb-9515-4ca406fbd6d5
[INFO  2018-03-08 11:39:05][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 11:39:05][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 11:39:06][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 11:39:06][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61943.
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Server created on 61943
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 11:39:06][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:61943 with 2.4 GB RAM, BlockManagerId(driver, localhost, 61943)
[INFO  2018-03-08 11:39:06][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 11:39:07][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:46
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:46) with 2 output partitions
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOps.scala:46)
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (MapPartitionsRDD[1] at flatMap at TransFomationOps.scala:45), which has no missing parents
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 1912.0 B, free 1912.0 B)
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1216.0 B, free 3.1 KB)
[INFO  2018-03-08 11:39:07][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:61943 (size: 1216.0 B, free: 2.4 GB)
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at flatMap at TransFomationOps.scala:45)
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 11:39:07][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2103 bytes)
[INFO  2018-03-08 11:39:07][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2122 bytes)
[INFO  2018-03-08 11:39:07][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 11:39:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 11:39:07][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 11:39:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 11:39:07][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 52 ms on localhost (1/2)
[INFO  2018-03-08 11:39:07][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 84 ms on localhost (2/2)
[INFO  2018-03-08 11:39:07][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 11:39:07][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOps.scala:46) finished in 0.105 s
[INFO  2018-03-08 11:39:07][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:46, took 0.433967 s
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 11:39:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 11:39:07][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 11:39:07][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 11:39:07][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 11:39:07][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 11:39:07][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 11:39:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 11:39:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 11:39:07][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 11:39:07][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 11:39:07][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 11:39:07][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-b3a9b82b-1f51-4e7f-9350-6c9650657593
[INFO  2018-03-08 13:48:57][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 13:48:58][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 13:48:58][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 13:48:58][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 13:48:58][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 13:48:58][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 13:49:00][main] Logging$class:58 Successfully started service 'sparkDriver' on port 64097.
[INFO  2018-03-08 13:49:00][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 13:49:00][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 13:49:01][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:64110]
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 64110.
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-35ea4322-29ad-4066-a864-b45c9c716a84
[INFO  2018-03-08 13:49:01][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 13:49:01][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 13:49:01][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64153.
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Server created on 64153
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 13:49:01][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:64153 with 2.4 GB RAM, BlockManagerId(driver, localhost, 64153)
[INFO  2018-03-08 13:49:01][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 13:49:02][main] Logging$class:58 Starting job: count at TransFomationOps.scala:63
[INFO  2018-03-08 13:49:02][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOps.scala:63) with 2 output partitions
[INFO  2018-03-08 13:49:02][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOps.scala:63)
[INFO  2018-03-08 13:49:02][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 13:49:02][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62), which has no missing parents
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.3 KB, free 18.3 KB)
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.5 KB, free 25.7 KB)
[INFO  2018-03-08 13:49:03][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:64153 (size: 7.5 KB, free: 2.4 GB)
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62)
[INFO  2018-03-08 13:49:03][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 13:49:03][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 13:49:03][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 13:49:04][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 13:49:04][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 13:49:04][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 13:49:04][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 13:49:04][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 162 ms on localhost (1/2)
[INFO  2018-03-08 13:49:04][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 126 ms on localhost (2/2)
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOps.scala:63) finished in 0.319 s
[INFO  2018-03-08 13:49:04][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 13:49:04][main] Logging$class:58 Job 0 finished: count at TransFomationOps.scala:63, took 1.198234 s
[INFO  2018-03-08 13:49:04][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:64
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOps.scala:64) with 2 output partitions
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:64)
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62), which has no missing parents
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.4 KB, free 44.1 KB)
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 51.7 KB)
[INFO  2018-03-08 13:49:04][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:64153 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62)
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 13:49:04][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 13:49:04][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 13:49:04][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 13:49:04][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 13:49:04][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 13:49:04][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 13:49:04][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 39 ms on localhost (1/2)
[INFO  2018-03-08 13:49:04][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 31 ms on localhost (2/2)
[INFO  2018-03-08 13:49:04][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 13:49:04][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:64) finished in 0.044 s
[INFO  2018-03-08 13:49:04][main] Logging$class:58 Job 1 finished: foreach at TransFomationOps.scala:64, took 0.118783 s
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 13:49:04][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[WARN  2018-03-08 13:49:04][main] QueuedThreadPool:145 4 threads could not be stopped
[INFO  2018-03-08 13:49:04][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 13:49:04][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 13:49:04][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 13:49:04][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 13:49:04][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 13:49:04][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 13:49:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 13:49:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 13:49:04][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 13:49:04][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 13:49:04][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-5117827a-76de-47ee-9c6c-61a61b4286b7
[INFO  2018-03-08 14:01:31][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:01:32][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:01:33][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:24)
[INFO  2018-03-08 14:01:33][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:01:33][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:01:33][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:01:34][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55387.
[INFO  2018-03-08 14:01:35][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:01:35][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:01:35][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55432]
[INFO  2018-03-08 14:01:35][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55432.
[INFO  2018-03-08 14:01:35][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:01:35][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:01:35][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-58c962b2-bf5e-4bba-8b11-b40c3d2b713e
[INFO  2018-03-08 14:01:35][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:01:35][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:01:36][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:01:36][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55451.
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Server created on 55451
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:01:36][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:55451 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55451)
[INFO  2018-03-08 14:01:36][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:01:36][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:01:36][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:01:36][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:01:36][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:01:36][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-34440ba7-6b2b-4db0-9f41-6d0e89766cd3
[INFO  2018-03-08 14:01:36][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:12:33][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:12:34][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:12:35][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:12:35][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:12:35][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:12:35][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:12:37][main] Logging$class:58 Successfully started service 'sparkDriver' on port 61464.
[INFO  2018-03-08 14:12:37][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:12:37][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:12:37][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:61485]
[INFO  2018-03-08 14:12:37][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 61485.
[INFO  2018-03-08 14:12:37][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:12:37][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:12:37][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-f88c7071-b183-42bb-94ae-5767d46473d0
[INFO  2018-03-08 14:12:37][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:12:38][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:12:38][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61496.
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Server created on 61496
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:12:38][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:61496 with 2.4 GB RAM, BlockManagerId(driver, localhost, 61496)
[INFO  2018-03-08 14:12:38][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:12:39][main] Logging$class:58 Starting job: count at TransFomationOfJavaOps.java:111
[INFO  2018-03-08 14:12:39][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOfJavaOps.java:111) with 2 output partitions
[INFO  2018-03-08 14:12:39][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:12:39][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:12:39][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:12:39][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110), which has no missing parents
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.5 KB, free 18.5 KB)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.6 KB, free 26.0 KB)
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:61496 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:12:40][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:12:40][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:12:40][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:12:40][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:12:40][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 169 ms on localhost (1/2)
[INFO  2018-03-08 14:12:40][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 130 ms on localhost (2/2)
[INFO  2018-03-08 14:12:40][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOfJavaOps.java:111) finished in 0.209 s
[INFO  2018-03-08 14:12:40][main] Logging$class:58 Job 0 finished: count at TransFomationOfJavaOps.java:111, took 0.565108 s
[INFO  2018-03-08 14:12:40][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:112
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOfJavaOps.java:112) with 2 output partitions
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:112)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110), which has no missing parents
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.7 KB, free 44.7 KB)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 52.5 KB)
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:61496 (size: 7.7 KB, free: 2.4 GB)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110)
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:12:40][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:12:40][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:12:40][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:12:40][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:12:40][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 47 ms on localhost (1/2)
[INFO  2018-03-08 14:12:40][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (2/2)
[INFO  2018-03-08 14:12:40][task-result-getter-2] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:12:40][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:112) finished in 0.049 s
[INFO  2018-03-08 14:12:40][main] Logging$class:58 Job 1 finished: foreach at TransFomationOfJavaOps.java:112, took 0.072602 s
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:12:40][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:12:40][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:12:40][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:12:40][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:12:40][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:12:40][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:12:40][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:12:40][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:12:40][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:12:40][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:12:40][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-8862dc12-ef49-4f29-8306-09cf16a9f87e
[INFO  2018-03-08 14:13:02][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:13:03][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:13:03][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:13:04][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:13:04][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:13:04][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:13:05][main] Logging$class:58 Successfully started service 'sparkDriver' on port 61915.
[INFO  2018-03-08 14:13:05][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:13:05][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:13:06][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:61952]
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 61952.
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-5c8b259f-9b38-46a8-93f8-906625051a04
[INFO  2018-03-08 14:13:06][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:13:06][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:13:06][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61981.
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Server created on 61981
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:13:06][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:61981 with 2.4 GB RAM, BlockManagerId(driver, localhost, 61981)
[INFO  2018-03-08 14:13:06][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:13:07][main] Logging$class:58 Starting job: count at TransFomationOfJavaOps.java:111
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOfJavaOps.java:111) with 2 output partitions
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110), which has no missing parents
[INFO  2018-03-08 14:13:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.5 KB, free 18.5 KB)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.6 KB, free 26.0 KB)
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:61981 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:13:08][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:13:08][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:13:08][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:13:08][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:13:08][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 93 ms on localhost (1/2)
[INFO  2018-03-08 14:13:08][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 145 ms on localhost (2/2)
[INFO  2018-03-08 14:13:08][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOfJavaOps.java:111) finished in 0.168 s
[INFO  2018-03-08 14:13:08][main] Logging$class:58 Job 0 finished: count at TransFomationOfJavaOps.java:111, took 0.580663 s
[INFO  2018-03-08 14:13:08][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:112
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOfJavaOps.java:112) with 2 output partitions
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:112)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110), which has no missing parents
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.7 KB, free 44.7 KB)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 52.5 KB)
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:61981 (size: 7.7 KB, free: 2.4 GB)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:110)
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 27234 bytes)
[INFO  2018-03-08 14:13:08][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:13:08][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:13:08][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:13:08][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 21 ms on localhost (1/2)
[INFO  2018-03-08 14:13:08][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:13:08][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 29 ms on localhost (2/2)
[INFO  2018-03-08 14:13:08][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:13:08][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:112) finished in 0.030 s
[INFO  2018-03-08 14:13:08][main] Logging$class:58 Job 1 finished: foreach at TransFomationOfJavaOps.java:112, took 0.048251 s
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:13:08][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:13:08][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:13:08][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:13:08][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:13:08][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:13:08][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:13:08][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:13:08][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:13:08][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:13:08][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:13:08][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-8ff74b24-e407-4dc3-a322-3da70b4696f5
[INFO  2018-03-08 14:13:45][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:13:46][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:13:47][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:13:47][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:13:47][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:13:47][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:13:48][main] Logging$class:58 Successfully started service 'sparkDriver' on port 62333.
[INFO  2018-03-08 14:13:49][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:13:49][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:13:49][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:62354]
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 62354.
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-2b9f1ca4-998c-474c-aada-867333da350b
[INFO  2018-03-08 14:13:49][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:13:49][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:13:49][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:13:49][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:13:50][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:13:50][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62366.
[INFO  2018-03-08 14:13:50][main] Logging$class:58 Server created on 62366
[INFO  2018-03-08 14:13:50][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:13:50][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:62366 with 2.4 GB RAM, BlockManagerId(driver, localhost, 62366)
[INFO  2018-03-08 14:13:50][main] Logging$class:58 Registered BlockManager
[WARN  2018-03-08 14:14:23][driver-heartbeater] Logging$class:91 Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@566db0a6,BlockManagerId(driver, localhost, 62366))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:476)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:505)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:505)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:505)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1801)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:505)
	at java.util.concurrent.Executors$RunnableAdapter.call$$$capture(Executors.java:511)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:107)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 15 more
[WARN  2018-03-08 14:14:23][heartbeat-receiver-event-loop-thread] Logging$class:70 Ignored message: HeartbeatResponse(false)
[INFO  2018-03-08 14:16:25][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:16:26][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:16:27][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:16:27][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:16:27][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:16:27][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:16:29][main] Logging$class:58 Successfully started service 'sparkDriver' on port 64229.
[INFO  2018-03-08 14:16:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:16:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:16:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:64266]
[INFO  2018-03-08 14:16:29][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 64266.
[INFO  2018-03-08 14:16:29][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:16:29][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:16:29][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-24a8841b-d885-41ed-a6ff-786ad49fc1c9
[INFO  2018-03-08 14:16:29][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:16:30][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:16:30][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64303.
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Server created on 64303
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:16:30][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:64303 with 2.4 GB RAM, BlockManagerId(driver, localhost, 64303)
[INFO  2018-03-08 14:16:30][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:16:49][main] Logging$class:58 Starting job: count at TransFomationOfJavaOps.java:112
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOfJavaOps.java:112) with 2 output partitions
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOfJavaOps.java:112)
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111), which has no missing parents
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.5 KB, free 18.5 KB)
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.6 KB, free 26.0 KB)
[INFO  2018-03-08 14:16:49][dispatcher-event-loop-2] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:64303 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:16:49][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:16:50][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:16:50][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:16:50][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:16:50][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:16:50][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 141 ms on localhost (1/2)
[INFO  2018-03-08 14:16:50][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 210 ms on localhost (2/2)
[INFO  2018-03-08 14:16:50][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOfJavaOps.java:112) finished in 0.233 s
[INFO  2018-03-08 14:16:50][main] Logging$class:58 Job 0 finished: count at TransFomationOfJavaOps.java:112, took 0.573135 s
[INFO  2018-03-08 14:16:50][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:113
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOfJavaOps.java:113) with 2 output partitions
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:113)
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111), which has no missing parents
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.7 KB, free 44.7 KB)
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 52.5 KB)
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-0] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:64303 (size: 7.7 KB, free: 2.4 GB)
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:16:50][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:16:50][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:16:50][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:16:50][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:16:50][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 46 ms on localhost (1/2)
[INFO  2018-03-08 14:16:50][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 58 ms on localhost (2/2)
[INFO  2018-03-08 14:16:50][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:16:50][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:113) finished in 0.060 s
[INFO  2018-03-08 14:16:50][main] Logging$class:58 Job 1 finished: foreach at TransFomationOfJavaOps.java:113, took 0.082477 s
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:16:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:16:50][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:16:50][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:16:50][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:16:50][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:16:50][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:16:50][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:16:50][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:16:50][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:16:50][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:16:50][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-2be4c79a-3f59-48b6-8079-76f48cdd795f
[INFO  2018-03-08 14:18:43][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:18:44][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:18:45][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:18:45][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:18:45][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:18:45][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:18:47][main] Logging$class:58 Successfully started service 'sparkDriver' on port 49745.
[INFO  2018-03-08 14:18:47][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:18:47][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:18:48][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:49766]
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 49766.
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-6812a625-259d-4803-91ff-ecee7b6b5142
[INFO  2018-03-08 14:18:48][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:18:48][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:18:48][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49777.
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Server created on 49777
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:18:48][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:49777 with 2.4 GB RAM, BlockManagerId(driver, localhost, 49777)
[INFO  2018-03-08 14:18:48][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:18:49][main] Logging$class:58 Starting job: count at TransFomationOfJavaOps.java:112
[INFO  2018-03-08 14:18:49][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOfJavaOps.java:112) with 2 output partitions
[INFO  2018-03-08 14:18:49][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOfJavaOps.java:112)
[INFO  2018-03-08 14:18:49][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:18:49][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:18:49][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111), which has no missing parents
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.5 KB, free 18.5 KB)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.6 KB, free 26.0 KB)
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:49777 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:18:50][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:18:50][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:18:50][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:18:50][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:18:50][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 126 ms on localhost (1/2)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOfJavaOps.java:112) finished in 0.209 s
[INFO  2018-03-08 14:18:50][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 188 ms on localhost (2/2)
[INFO  2018-03-08 14:18:50][main] Logging$class:58 Job 0 finished: count at TransFomationOfJavaOps.java:112, took 0.571810 s
[INFO  2018-03-08 14:18:50][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:18:50][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:113
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOfJavaOps.java:113) with 2 output partitions
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:113)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111), which has no missing parents
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.7 KB, free 44.7 KB)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 52.5 KB)
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:49777 (size: 7.7 KB, free: 2.4 GB)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:18:50][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:18:50][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:18:50][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:18:50][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:18:50][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 65 ms on localhost (1/2)
[INFO  2018-03-08 14:18:50][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 63 ms on localhost (2/2)
[INFO  2018-03-08 14:18:50][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:113) finished in 0.073 s
[INFO  2018-03-08 14:18:50][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:18:50][main] Logging$class:58 Job 1 finished: foreach at TransFomationOfJavaOps.java:113, took 0.093686 s
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:18:50][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[WARN  2018-03-08 14:18:50][main] QueuedThreadPool:145 1 threads could not be stopped
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:151 Couldn't stop Thread[qtp505968231-53,5,main]
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:154  at java.util.concurrent.ConcurrentHashMap.replaceNode(ConcurrentHashMap.java:1120)
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:154  at java.util.concurrent.ConcurrentHashMap.remove(ConcurrentHashMap.java:1097)
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:154  at org.spark-project.jetty.util.ConcurrentHashSet.remove(ConcurrentHashSet.java:88)
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:154  at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:594)
[INFO  2018-03-08 14:18:50][main] QueuedThreadPool:154  at java.lang.Thread.run(Thread.java:748)
[INFO  2018-03-08 14:18:50][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:18:50][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:18:50][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:18:50][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:18:50][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:18:50][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:18:50][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:18:50][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:18:50][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-c74b01e2-95d8-4eb2-88e5-675a7b3262ef
[INFO  2018-03-08 14:18:50][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:20:00][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:20:02][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:20:02][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.TransFormation.TransFomationOfJavaOps.main(TransFomationOfJavaOps.java:25)
[INFO  2018-03-08 14:20:02][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:20:02][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:20:02][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:20:04][main] Logging$class:58 Successfully started service 'sparkDriver' on port 50468.
[INFO  2018-03-08 14:20:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:20:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:20:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:50489]
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 50489.
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-e938264c-8b89-4cc8-8a3c-92cd0f488047
[INFO  2018-03-08 14:20:05][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:20:05][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:20:05][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50516.
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Server created on 50516
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:20:05][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:50516 with 2.4 GB RAM, BlockManagerId(driver, localhost, 50516)
[INFO  2018-03-08 14:20:05][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:20:06][main] Logging$class:58 Starting job: count at TransFomationOfJavaOps.java:110
[INFO  2018-03-08 14:20:06][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOfJavaOps.java:110) with 2 output partitions
[INFO  2018-03-08 14:20:06][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOfJavaOps.java:110)
[INFO  2018-03-08 14:20:06][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:20:06][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:20:06][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:109), which has no missing parents
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.5 KB, free 18.5 KB)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.6 KB, free 26.0 KB)
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:50516 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:109)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:20:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:20:07][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:20:07][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:20:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:20:07][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 154 ms on localhost (1/2)
[INFO  2018-03-08 14:20:07][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 240 ms on localhost (2/2)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOfJavaOps.java:110) finished in 0.267 s
[INFO  2018-03-08 14:20:07][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:20:07][main] Logging$class:58 Job 0 finished: count at TransFomationOfJavaOps.java:110, took 0.631753 s
[INFO  2018-03-08 14:20:07][main] Logging$class:58 Starting job: foreach at TransFomationOfJavaOps.java:111
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOfJavaOps.java:111) with 2 output partitions
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOfJavaOps.java:111)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:109), which has no missing parents
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.7 KB, free 44.7 KB)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KB, free 52.5 KB)
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-0] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:50516 (size: 7.7 KB, free: 2.4 GB)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOfJavaOps.java:109)
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 52229 bytes)
[INFO  2018-03-08 14:20:07][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:20:07][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:20:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:20:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:20:07][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 123 ms on localhost (1/2)
[INFO  2018-03-08 14:20:07][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 140 ms on localhost (2/2)
[INFO  2018-03-08 14:20:07][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:20:07][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOfJavaOps.java:111) finished in 0.142 s
[INFO  2018-03-08 14:20:07][main] Logging$class:58 Job 1 finished: foreach at TransFomationOfJavaOps.java:111, took 0.169399 s
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:20:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:20:07][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:20:07][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:20:07][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:20:07][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:20:07][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:20:07][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:20:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:20:07][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:20:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:20:07][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-0e1bfc1a-dff2-4135-aa34-707b9ccbb809
[INFO  2018-03-08 14:26:55][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:26:56][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:26:56][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 14:26:56][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:26:56][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:26:56][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:26:58][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54728.
[INFO  2018-03-08 14:26:59][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:26:59][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:26:59][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54757]
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54757.
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-1c5ffe52-a2ad-49fd-bb1e-1dcc105ccdd7
[INFO  2018-03-08 14:26:59][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:26:59][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:26:59][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54776.
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Server created on 54776
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:26:59][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:54776 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54776)
[INFO  2018-03-08 14:26:59][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:27:00][main] Logging$class:58 Starting job: count at TransFomationOps.scala:63
[INFO  2018-03-08 14:27:00][dag-scheduler-event-loop] Logging$class:58 Got job 0 (count at TransFomationOps.scala:63) with 2 output partitions
[INFO  2018-03-08 14:27:00][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (count at TransFomationOps.scala:63)
[INFO  2018-03-08 14:27:00][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:27:00][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:27:00][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62), which has no missing parents
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 18.3 KB, free 18.3 KB)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.5 KB, free 25.7 KB)
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54776 (size: 7.5 KB, free: 2.4 GB)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 0 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 14:27:01][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:27:01][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:27:01][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
[INFO  2018-03-08 14:27:01][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
[INFO  2018-03-08 14:27:01][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 82 ms on localhost (1/2)
[INFO  2018-03-08 14:27:01][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 57 ms on localhost (2/2)
[INFO  2018-03-08 14:27:01][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (count at TransFomationOps.scala:63) finished in 0.102 s
[INFO  2018-03-08 14:27:01][main] Logging$class:58 Job 0 finished: count at TransFomationOps.scala:63, took 0.369546 s
[INFO  2018-03-08 14:27:01][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:64
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOps.scala:64) with 2 output partitions
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:64)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62), which has no missing parents
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 18.4 KB, free 44.1 KB)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 51.7 KB)
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:54776 (size: 7.6 KB, free: 2.4 GB)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[1] at sample at TransFomationOps.scala:62)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 14:27:01][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:27:01][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:27:01][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:01][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:01][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 14 ms on localhost (1/2)
[INFO  2018-03-08 14:27:01][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 16 ms on localhost (2/2)
[INFO  2018-03-08 14:27:01][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:64) finished in 0.016 s
[INFO  2018-03-08 14:27:01][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:27:01][main] Logging$class:58 Job 1 finished: foreach at TransFomationOps.scala:64, took 0.030315 s
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:27:01][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:27:01][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:27:01][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:27:01][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:27:01][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:27:01][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:27:01][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:27:01][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:27:01][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:27:01][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:27:01][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-8defeecd-295c-4e99-b45a-c7b562dee9ad
[INFO  2018-03-08 14:27:26][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:27:27][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:27:27][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 14:27:28][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:27:28][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:27:28][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:27:29][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55049.
[INFO  2018-03-08 14:27:30][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:27:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:27:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55062]
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55062.
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-8ba0e6be-8676-4e60-86af-def016abc115
[INFO  2018-03-08 14:27:30][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:27:30][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:27:30][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:27:30][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:27:31][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55076.
[INFO  2018-03-08 14:27:31][main] Logging$class:58 Server created on 55076
[INFO  2018-03-08 14:27:31][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:27:31][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:55076 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55076)
[INFO  2018-03-08 14:27:31][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:27:31][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:79
[INFO  2018-03-08 14:27:31][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:79) with 4 output partitions
[INFO  2018-03-08 14:27:31][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 0 (foreach at TransFomationOps.scala:79)
[INFO  2018-03-08 14:27:31][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 14:27:31][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 14:27:31][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 0 (UnionRDD[2] at union at TransFomationOps.scala:78), which has no missing parents
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 1960.0 B, free 1960.0 B)
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1331.0 B, free 3.2 KB)
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:55076 (size: 1331.0 B, free: 2.4 GB)
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 Submitting 4 missing tasks from ResultStage 0 (UnionRDD[2] at union at TransFomationOps.scala:78)
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 4 tasks
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 14:27:32][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:27:32][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:27:32][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:32][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-0] Logging$class:58 Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2187 bytes)
[INFO  2018-03-08 14:27:32][Executor task launch worker-1] Logging$class:58 Running task 2.0 in stage 0.0 (TID 2)
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-0] Logging$class:58 Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2244 bytes)
[INFO  2018-03-08 14:27:32][Executor task launch worker-0] Logging$class:58 Running task 3.0 in stage 0.0 (TID 3)
[INFO  2018-03-08 14:27:32][Executor task launch worker-1] Logging$class:58 Finished task 2.0 in stage 0.0 (TID 2). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:32][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 45 ms on localhost (1/4)
[INFO  2018-03-08 14:27:32][Executor task launch worker-0] Logging$class:58 Finished task 3.0 in stage 0.0 (TID 3). 915 bytes result sent to driver
[INFO  2018-03-08 14:27:32][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 94 ms on localhost (2/4)
[INFO  2018-03-08 14:27:32][task-result-getter-2] Logging$class:58 Finished task 2.0 in stage 0.0 (TID 2) in 14 ms on localhost (3/4)
[INFO  2018-03-08 14:27:32][task-result-getter-3] Logging$class:58 Finished task 3.0 in stage 0.0 (TID 3) in 13 ms on localhost (4/4)
[INFO  2018-03-08 14:27:32][dag-scheduler-event-loop] Logging$class:58 ResultStage 0 (foreach at TransFomationOps.scala:79) finished in 0.112 s
[INFO  2018-03-08 14:27:32][task-result-getter-3] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:27:32][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:79, took 0.394553 s
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:27:32][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:27:32][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:27:32][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:27:32][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:27:32][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:27:32][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:27:32][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:27:32][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:27:32][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:27:32][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:27:32][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-a7d27abc-4859-41fc-b5f3-09225f3d1b9f
[INFO  2018-03-08 14:48:29][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 14:48:30][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 14:48:30][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 14:48:31][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 14:48:31][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 14:48:31][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 14:48:32][main] Logging$class:58 Successfully started service 'sparkDriver' on port 56250.
[INFO  2018-03-08 14:48:32][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 14:48:32][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 14:48:32][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:56263]
[INFO  2018-03-08 14:48:32][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 56263.
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-25cb4c1d-6eb5-4d82-bd36-3e1069c45b31
[INFO  2018-03-08 14:48:33][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 14:48:33][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 14:48:33][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56283.
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Server created on 56283
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 14:48:33][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:56283 with 2.4 GB RAM, BlockManagerId(driver, localhost, 56283)
[INFO  2018-03-08 14:48:33][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 14:48:34][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:94
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:92)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:94) with 2 output partitions
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:94)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92), which has no missing parents
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.7 KB, free 3.7 KB)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.0 KB, free 5.7 KB)
[INFO  2018-03-08 14:48:34][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:56283 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92)
[INFO  2018-03-08 14:48:34][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 14:48:35][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 149 ms on localhost (1/2)
[INFO  2018-03-08 14:48:35][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 121 ms on localhost (2/2)
[INFO  2018-03-08 14:48:35][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:92) finished in 0.179 s
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 10.2 KB)
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 12.5 KB)
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:56283 (size: 2.3 KB, free: 2.4 GB)
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93)
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 14:48:35][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 14:48:35][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 14:48:35][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 65 ms on localhost (1/2)
[INFO  2018-03-08 14:48:35][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 63 ms on localhost (2/2)
[INFO  2018-03-08 14:48:35][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 14:48:35][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:94) finished in 0.067 s
[INFO  2018-03-08 14:48:35][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:94, took 0.529880 s
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 14:48:35][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 14:48:35][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 14:48:35][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 14:48:35][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 14:48:35][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 14:48:35][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 14:48:35][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 14:48:35][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 14:48:35][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 14:48:35][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 14:48:35][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-51ef7648-878c-414e-a5d5-acafa469bbb5
[INFO  2018-03-08 15:00:00][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 15:00:01][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 15:00:01][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 15:00:01][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 15:00:01][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 15:00:01][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 15:00:02][main] Logging$class:58 Successfully started service 'sparkDriver' on port 64030.
[INFO  2018-03-08 15:00:03][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 15:00:03][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 15:00:03][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:64043]
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 64043.
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-35fa574d-e965-4f8b-8bed-f85625eeadf8
[INFO  2018-03-08 15:00:03][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 15:00:03][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 15:00:03][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 15:00:03][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 15:00:04][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 15:00:04][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64054.
[INFO  2018-03-08 15:00:04][main] Logging$class:58 Server created on 64054
[INFO  2018-03-08 15:00:04][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 15:00:04][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:64054 with 2.4 GB RAM, BlockManagerId(driver, localhost, 64054)
[INFO  2018-03-08 15:00:04][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:94
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:92)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:94) with 2 output partitions
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:94)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92), which has no missing parents
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.7 KB, free 3.7 KB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.0 KB, free 5.7 KB)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:64054 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 15:00:05][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 199 ms on localhost (1/2)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 15:00:05][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 250 ms on localhost (2/2)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:92) finished in 0.261 s
[INFO  2018-03-08 15:00:05][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 10.2 KB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 12.5 KB)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:64054 (size: 2.3 KB, free: 2.4 GB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 7 ms
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 7 ms
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 15:00:05][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 55 ms on localhost (1/2)
[INFO  2018-03-08 15:00:05][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 59 ms on localhost (2/2)
[INFO  2018-03-08 15:00:05][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:94) finished in 0.061 s
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:94, took 0.611088 s
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:102
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Size of output statuses for shuffle 0 is 154 bytes
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOps.scala:102) with 2 output partitions
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 3 (foreach at TransFomationOps.scala:102)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 2)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:97), which has no missing parents
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 4.6 KB, free 17.1 KB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 19.5 KB)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-0] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:64054 (size: 2.4 KB, free: 2.4 GB)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:97)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 Adding task set 3.0 with 2 tasks
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 3.0 (TID 5)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 3.0 (TID 4)
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 15:00:05][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-08 15:00:05][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 15:00:05][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 4) in 13 ms on localhost (1/2)
[INFO  2018-03-08 15:00:05][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 5) in 13 ms on localhost (2/2)
[INFO  2018-03-08 15:00:05][dag-scheduler-event-loop] Logging$class:58 ResultStage 3 (foreach at TransFomationOps.scala:102) finished in 0.019 s
[INFO  2018-03-08 15:00:05][task-result-getter-1] Logging$class:58 Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Job 1 finished: foreach at TransFomationOps.scala:102, took 0.039191 s
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 15:00:05][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 15:00:05][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 15:00:05][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 15:00:05][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 15:00:05][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 15:00:05][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 15:00:05][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 15:00:05][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 15:00:06][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 15:00:06][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-82562a44-a9b6-4755-a747-417f4b8c17cc
[INFO  2018-03-08 15:01:44][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 15:01:45][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 15:01:46][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 15:01:46][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 15:01:46][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 15:01:46][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 15:01:47][main] Logging$class:58 Successfully started service 'sparkDriver' on port 49412.
[INFO  2018-03-08 15:01:48][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 15:01:48][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 15:01:48][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:49443]
[INFO  2018-03-08 15:01:48][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 49443.
[INFO  2018-03-08 15:01:48][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 15:01:48][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 15:01:48][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-e9af8c9e-2f7b-4fe5-9e0c-b9f14bdb4025
[INFO  2018-03-08 15:01:48][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 15:01:49][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 15:01:49][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49457.
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Server created on 49457
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 15:01:49][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:49457 with 2.4 GB RAM, BlockManagerId(driver, localhost, 49457)
[INFO  2018-03-08 15:01:49][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 15:01:50][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:94
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:92)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:94) with 2 output partitions
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:94)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92), which has no missing parents
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.7 KB, free 3.7 KB)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.0 KB, free 5.7 KB)
[INFO  2018-03-08 15:01:50][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:49457 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:92)
[INFO  2018-03-08 15:01:50][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 15:01:50][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 15:01:50][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 15:01:50][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 15:01:50][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 15:01:51][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 117 ms on localhost (1/2)
[INFO  2018-03-08 15:01:51][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 147 ms on localhost (2/2)
[INFO  2018-03-08 15:01:51][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:92) finished in 0.173 s
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 10.2 KB)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 12.5 KB)
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:49457 (size: 2.3 KB, free: 2.4 GB)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 15:01:51][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 60 ms on localhost (1/2)
[INFO  2018-03-08 15:01:51][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 64 ms on localhost (2/2)
[INFO  2018-03-08 15:01:51][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:94) finished in 0.064 s
[INFO  2018-03-08 15:01:51][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:94, took 0.570658 s
[INFO  2018-03-08 15:01:51][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:102
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Size of output statuses for shuffle 0 is 154 bytes
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOps.scala:102) with 2 output partitions
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 3 (foreach at TransFomationOps.scala:102)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 2)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:97), which has no missing parents
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 4.6 KB, free 17.1 KB)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 19.5 KB)
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:49457 (size: 2.4 KB, free: 2.4 GB)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:97)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 Adding task set 3.0 with 2 tasks
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 3.0 (TID 4)
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 3.0 (TID 5)
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 15:01:51][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 15:01:51][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-08 15:01:51][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 5) in 15 ms on localhost (1/2)
[INFO  2018-03-08 15:01:51][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 4) in 18 ms on localhost (2/2)
[INFO  2018-03-08 15:01:51][dag-scheduler-event-loop] Logging$class:58 ResultStage 3 (foreach at TransFomationOps.scala:102) finished in 0.018 s
[INFO  2018-03-08 15:01:51][task-result-getter-0] Logging$class:58 Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:01:51][main] Logging$class:58 Job 1 finished: foreach at TransFomationOps.scala:102, took 0.039332 s
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 15:01:51][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 15:01:51][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 15:01:51][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 15:01:51][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 15:01:51][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 15:01:51][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 15:01:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 15:01:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 15:01:51][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 15:01:51][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 15:01:51][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-e64e290e-2c4a-4a23-a4df-13ae9978a459
[INFO  2018-03-08 15:01:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting shut down.
[INFO  2018-03-08 15:11:01][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 15:11:02][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 15:11:03][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 15:11:03][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 15:11:03][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 15:11:03][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 15:11:04][main] Logging$class:58 Successfully started service 'sparkDriver' on port 58372.
[INFO  2018-03-08 15:11:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 15:11:05][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 15:11:05][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:58394]
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 58394.
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-94169cda-ab51-49f8-98b2-8a11fafb5d48
[INFO  2018-03-08 15:11:05][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 15:11:05][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 15:11:05][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 15:11:05][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 15:11:06][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 15:11:06][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58406.
[INFO  2018-03-08 15:11:06][main] Logging$class:58 Server created on 58406
[INFO  2018-03-08 15:11:06][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 15:11:06][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:58406 with 2.4 GB RAM, BlockManagerId(driver, localhost, 58406)
[INFO  2018-03-08 15:11:06][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 15:11:07][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:93
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:93)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:93) with 2 output partitions
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:93)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.8 KB, free 3.8 KB)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.0 KB, free 5.8 KB)
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:58406 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:93)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 15:11:07][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 179 ms on localhost (1/2)
[INFO  2018-03-08 15:11:07][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 217 ms on localhost (2/2)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:93) finished in 0.232 s
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 15:11:07][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.5 KB, free 10.3 KB)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 12.6 KB)
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:58406 (size: 2.3 KB, free: 2.4 GB)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at groupByKey at TransFomationOps.scala:93)
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 8 ms
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 8 ms
[INFO  2018-03-08 15:11:07][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 15:11:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 15:11:07][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 63 ms on localhost (1/2)
[INFO  2018-03-08 15:11:07][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 69 ms on localhost (2/2)
[INFO  2018-03-08 15:11:07][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:11:07][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:93) finished in 0.070 s
[INFO  2018-03-08 15:11:07][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:93, took 0.672188 s
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 15:11:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 15:11:07][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 15:11:07][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 15:11:07][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 15:11:07][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 15:11:07][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 15:11:07][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 15:11:07][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 15:11:07][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 15:11:07][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 15:11:07][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-e346a91b-2c9a-455d-802e-44294245d77f
[INFO  2018-03-08 15:12:13][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 15:12:15][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 15:12:15][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 15:12:15][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 15:12:15][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 15:12:15][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 15:12:16][main] Logging$class:58 Successfully started service 'sparkDriver' on port 58975.
[INFO  2018-03-08 15:12:17][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 15:12:17][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 15:12:17][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 58996.
[INFO  2018-03-08 15:12:17][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:58996]
[INFO  2018-03-08 15:12:17][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 15:12:17][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 15:12:17][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-cb6fbe7e-97f5-4c6e-86af-33c054584873
[INFO  2018-03-08 15:12:17][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 15:12:17][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 15:12:18][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 15:12:18][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59023.
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Server created on 59023
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 15:12:18][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:59023 with 2.4 GB RAM, BlockManagerId(driver, localhost, 59023)
[INFO  2018-03-08 15:12:18][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 15:12:19][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:93
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:93)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:93) with 2 output partitions
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:93)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.9 KB, free 2.9 KB)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1721.0 B, free 4.6 KB)
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:59023 (size: 1721.0 B, free: 2.4 GB)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:93)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2092 bytes)
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2111 bytes)
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 15:12:19][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 132 ms on localhost (1/2)
[INFO  2018-03-08 15:12:19][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 168 ms on localhost (2/2)
[INFO  2018-03-08 15:12:19][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:93) finished in 0.190 s
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at reduceByKey at TransFomationOps.scala:93), which has no missing parents
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 2.6 KB, free 7.1 KB)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 1598.0 B, free 8.7 KB)
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:59023 (size: 1598.0 B, free: 2.4 GB)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[3] at reduceByKey at TransFomationOps.scala:93)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 15:12:19][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-08 15:12:19][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 15:12:19][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 43 ms on localhost (1/2)
[INFO  2018-03-08 15:12:19][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 48 ms on localhost (2/2)
[INFO  2018-03-08 15:12:19][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:93) finished in 0.050 s
[INFO  2018-03-08 15:12:19][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 15:12:19][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:93, took 0.613936 s
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 15:12:19][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 15:12:19][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 15:12:19][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 15:12:19][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 15:12:19][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 15:12:19][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 15:12:19][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 15:12:19][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 15:12:19][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 15:12:19][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-a00c3163-a8ad-4ad3-96cb-916eaf5d0342
[INFO  2018-03-08 15:12:19][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:04:39][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 17:04:40][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 17:04:40][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 17:04:40][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 17:04:40][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 17:04:40][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Successfully started service 'sparkDriver' on port 57679.
[INFO  2018-03-08 17:04:42][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 17:04:42][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 17:04:42][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:57692]
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 57692.
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-cfc059e9-cdd8-4eac-bf2d-140b69c64ba1
[INFO  2018-03-08 17:04:42][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 17:04:42][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 17:04:43][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 17:04:43][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57711.
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Server created on 57711
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 17:04:43][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:57711 with 2.4 GB RAM, BlockManagerId(driver, localhost, 57711)
[INFO  2018-03-08 17:04:43][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 17:04:44][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:139
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (map at TransFomationOps.scala:128)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Registering RDD 3 (map at TransFomationOps.scala:133)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:139) with 2 output partitions
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 2 (foreach at TransFomationOps.scala:139)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:128), which has no missing parents
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.5 KB, free 2.5 KB)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1558.0 B, free 4.0 KB)
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:57711 (size: 1558.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at TransFomationOps.scala:128)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at TransFomationOps.scala:133), which has no missing parents
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 6.4 KB)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 1560.0 B, free 8.0 KB)
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:57711 (size: 1560.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at TransFomationOps.scala:133)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2080 bytes)
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2076 bytes)
[INFO  2018-03-08 17:04:44][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 17:04:44][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 17:04:44][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 17:04:44][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2085 bytes)
[INFO  2018-03-08 17:04:44][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 17:04:44][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2101 bytes)
[INFO  2018-03-08 17:04:44][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 17:04:44][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 144 ms on localhost (1/2)
[INFO  2018-03-08 17:04:44][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on localhost (2/2)
[INFO  2018-03-08 17:04:44][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (map at TransFomationOps.scala:128) finished in 0.222 s
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 running: Set(ShuffleMapStage 1)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:04:44][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:04:44][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1159 bytes result sent to driver
[INFO  2018-03-08 17:04:44][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 76 ms on localhost (1/2)
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1159 bytes result sent to driver
[INFO  2018-03-08 17:04:45][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 105 ms on localhost (2/2)
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 1 (map at TransFomationOps.scala:133) finished in 0.245 s
[INFO  2018-03-08 17:04:45][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 2 (MapPartitionsRDD[6] at join at TransFomationOps.scala:138), which has no missing parents
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 11.1 KB)
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1882.0 B, free 13.0 KB)
[INFO  2018-03-08 17:04:45][dispatcher-event-loop-0] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:57711 (size: 1882.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at join at TransFomationOps.scala:138)
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 Adding task set 2.0 with 2 tasks
[INFO  2018-03-08 17:04:45][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:04:45][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 2.0 (TID 4)
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 2.0 (TID 5)
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 17:04:45][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-08 17:04:45][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 17:04:45][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4) in 61 ms on localhost (1/2)
[INFO  2018-03-08 17:04:45][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5) in 59 ms on localhost (2/2)
[INFO  2018-03-08 17:04:45][task-result-getter-1] Logging$class:58 Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:04:45][dag-scheduler-event-loop] Logging$class:58 ResultStage 2 (foreach at TransFomationOps.scala:139) finished in 0.063 s
[INFO  2018-03-08 17:04:45][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:139, took 0.724459 s
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 17:04:45][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 17:04:45][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 17:04:45][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 17:04:45][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 17:04:45][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 17:04:45][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 17:04:45][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 17:04:45][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 17:04:45][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:04:45][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 17:04:45][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 17:04:45][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-b6def28c-6946-474f-a170-e5a18e4bd21d
[INFO  2018-03-08 17:08:35][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 17:08:37][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 17:08:37][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:14)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 17:08:37][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 17:08:37][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 17:08:37][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 17:08:39][main] Logging$class:58 Successfully started service 'sparkDriver' on port 59728.
[INFO  2018-03-08 17:08:39][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 17:08:40][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 17:08:40][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:59749]
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 59749.
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-0e2b55c9-23b2-4095-b172-72e20cba0362
[INFO  2018-03-08 17:08:40][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 17:08:40][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 17:08:40][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 17:08:40][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 17:08:41][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 17:08:41][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59768.
[INFO  2018-03-08 17:08:41][main] Logging$class:58 Server created on 59768
[INFO  2018-03-08 17:08:41][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 17:08:41][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:59768 with 2.4 GB RAM, BlockManagerId(driver, localhost, 59768)
[INFO  2018-03-08 17:08:41][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 17:08:42][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:139
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Registering RDD 3 (filter at TransFomationOps.scala:131)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Registering RDD 4 (map at TransFomationOps.scala:133)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:139) with 2 output partitions
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 2 (foreach at TransFomationOps.scala:139)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at TransFomationOps.scala:131), which has no missing parents
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.7 KB, free 2.7 KB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1648.0 B, free 4.3 KB)
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:59768 (size: 1648.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at TransFomationOps.scala:131)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at map at TransFomationOps.scala:133), which has no missing parents
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 6.8 KB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 1560.0 B, free 8.3 KB)
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:59768 (size: 1560.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at map at TransFomationOps.scala:133)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2080 bytes)
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2076 bytes)
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2085 bytes)
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 17:08:42][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 98 ms on localhost (1/2)
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2101 bytes)
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 17:08:42][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 165 ms on localhost (2/2)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (filter at TransFomationOps.scala:131) finished in 0.194 s
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 running: Set(ShuffleMapStage 1)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:08:42][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1159 bytes result sent to driver
[INFO  2018-03-08 17:08:42][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 64 ms on localhost (1/2)
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1159 bytes result sent to driver
[INFO  2018-03-08 17:08:42][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 102 ms on localhost (2/2)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 1 (map at TransFomationOps.scala:133) finished in 0.190 s
[INFO  2018-03-08 17:08:42][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 2 (MapPartitionsRDD[7] at join at TransFomationOps.scala:138), which has no missing parents
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 11.5 KB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1882.0 B, free 13.3 KB)
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-3] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:59768 (size: 1882.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at join at TransFomationOps.scala:138)
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 Adding task set 2.0 with 2 tasks
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 2.0 (TID 5)
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 2.0 (TID 4)
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Getting 1 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 17:08:42][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-08 17:08:42][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 17:08:42][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5) in 68 ms on localhost (1/2)
[INFO  2018-03-08 17:08:42][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4) in 73 ms on localhost (2/2)
[INFO  2018-03-08 17:08:42][task-result-getter-1] Logging$class:58 Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:08:42][dag-scheduler-event-loop] Logging$class:58 ResultStage 2 (foreach at TransFomationOps.scala:139) finished in 0.075 s
[INFO  2018-03-08 17:08:42][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:139, took 0.691484 s
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 17:08:42][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 17:08:42][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 17:08:42][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 17:08:42][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 17:08:42][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 17:08:42][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 17:08:42][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 17:08:42][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:08:42][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 17:08:42][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 17:08:42][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-1e44e711-0654-4b45-bce9-5b750c7a0b2c
[INFO  2018-03-08 17:51:48][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 17:51:49][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 17:51:49][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:16)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 17:51:49][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 17:51:49][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 17:51:49][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 17:51:51][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54624.
[INFO  2018-03-08 17:51:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 17:51:51][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 17:51:52][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54637]
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54637.
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-c01c5510-efe4-4fcc-a896-1770b0a29b27
[INFO  2018-03-08 17:51:52][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 17:51:52][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 17:51:52][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54656.
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Server created on 54656
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 17:51:52][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:54656 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54656)
[INFO  2018-03-08 17:51:52][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 17:51:53][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:141
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Registering RDD 3 (filter at TransFomationOps.scala:133)
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Registering RDD 4 (map at TransFomationOps.scala:135)
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:141) with 2 output partitions
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 2 (foreach at TransFomationOps.scala:141)
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at TransFomationOps.scala:133), which has no missing parents
[INFO  2018-03-08 17:51:53][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 2.7 KB, free 2.7 KB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1648.0 B, free 4.3 KB)
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54656 (size: 1648.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at filter at TransFomationOps.scala:133)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at map at TransFomationOps.scala:135), which has no missing parents
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 6.8 KB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 1560.0 B, free 8.3 KB)
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:54656 (size: 1560.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at map at TransFomationOps.scala:135)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 2 tasks
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2080 bytes)
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2076 bytes)
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1159 bytes result sent to driver
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2085 bytes)
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 17:51:54][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 82 ms on localhost (1/2)
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2101 bytes)
[INFO  2018-03-08 17:51:54][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (2/2)
[INFO  2018-03-08 17:51:54][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 3)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (filter at TransFomationOps.scala:133) finished in 0.178 s
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 running: Set(ShuffleMapStage 1)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1159 bytes result sent to driver
[INFO  2018-03-08 17:51:54][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 106 ms on localhost (1/2)
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3). 1159 bytes result sent to driver
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 1 (map at TransFomationOps.scala:135) finished in 0.185 s
[INFO  2018-03-08 17:51:54][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 3) in 96 ms on localhost (2/2)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:51:54][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 2)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 2 (MapPartitionsRDD[7] at join at TransFomationOps.scala:140), which has no missing parents
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 11.5 KB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1882.0 B, free 13.3 KB)
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:54656 (size: 1882.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at join at TransFomationOps.scala:140)
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 Adding task set 2.0 with 2 tasks
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 1967 bytes)
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 2.0 (TID 4)
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 2.0 (TID 5)
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Getting 1 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 17:51:54][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 17:51:54][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-08 17:51:54][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 5) in 63 ms on localhost (1/2)
[INFO  2018-03-08 17:51:54][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 4) in 67 ms on localhost (2/2)
[INFO  2018-03-08 17:51:54][task-result-getter-1] Logging$class:58 Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:51:54][dag-scheduler-event-loop] Logging$class:58 ResultStage 2 (foreach at TransFomationOps.scala:141) finished in 0.068 s
[INFO  2018-03-08 17:51:54][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:141, took 0.634007 s
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 17:51:54][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 17:51:54][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 17:51:54][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 17:51:54][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 17:51:54][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 17:51:54][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 17:51:54][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 17:51:54][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 17:51:54][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:51:54][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 17:51:54][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-b9ede972-c954-4f0f-a8f5-89ea94af02dd
[INFO  2018-03-08 17:52:25][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 17:52:27][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 17:52:27][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:16)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 17:52:27][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 17:52:27][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 17:52:27][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 17:52:28][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55071.
[INFO  2018-03-08 17:52:29][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 17:52:29][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 17:52:29][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55092]
[INFO  2018-03-08 17:52:29][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55092.
[INFO  2018-03-08 17:52:29][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 17:52:29][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 17:52:29][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-7dcbbb42-b26c-412c-bea8-b18eb42ea376
[INFO  2018-03-08 17:52:29][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 17:52:29][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 17:52:30][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 17:52:30][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55103.
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Server created on 55103
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 17:52:30][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:55103 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55103)
[INFO  2018-03-08 17:52:30][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 17:52:31][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 17:52:31][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 17:52:31][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 17:52:31][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 17:52:31][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 17:52:31][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 17:52:31][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 17:52:31][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 17:52:31][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 17:52:31][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:52:31][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 17:52:31][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-9ffcda68-1d06-4886-81f2-25455f7f82b3
[INFO  2018-03-08 17:53:23][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 17:53:24][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 17:53:24][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:16)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 17:53:24][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 17:53:24][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 17:53:24][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 17:53:26][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55741.
[INFO  2018-03-08 17:53:26][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 17:53:26][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 17:53:27][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55754]
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55754.
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-fabff0c0-09ec-4592-ab76-4516e2f63c11
[INFO  2018-03-08 17:53:27][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 17:53:27][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 17:53:27][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55773.
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Server created on 55773
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 17:53:27][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:55773 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55773)
[INFO  2018-03-08 17:53:27][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 17:53:28][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:173
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Registering RDD 1 (sortBy at TransFomationOps.scala:158)
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:173) with 1 output partitions
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:173)
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 17:53:28][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:158), which has no missing parents
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.4 KB, free 3.4 KB)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1987.0 B, free 5.3 KB)
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:55773 (size: 1987.0 B, free: 2.4 GB)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:158)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2105 bytes)
[INFO  2018-03-08 17:53:29][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 17:53:29][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1158 bytes result sent to driver
[INFO  2018-03-08 17:53:29][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 140 ms on localhost (1/2)
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1158 bytes result sent to driver
[INFO  2018-03-08 17:53:29][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 209 ms on localhost (2/2)
[INFO  2018-03-08 17:53:29][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (sortBy at TransFomationOps.scala:158) finished in 0.224 s
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:158), which has no missing parents
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 8.8 KB)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 10.9 KB)
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:55773 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:158)
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 5 ms
[INFO  2018-03-08 17:53:29][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 17:53:29][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 60 ms on localhost (1/1)
[INFO  2018-03-08 17:53:29][task-result-getter-2] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 17:53:29][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:173) finished in 0.061 s
[INFO  2018-03-08 17:53:29][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:173, took 0.638774 s
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 17:53:29][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 17:53:29][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 17:53:29][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 17:53:29][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 17:53:29][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 17:53:29][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 17:53:29][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 17:53:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 17:53:29][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 17:53:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 17:53:29][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-1d93fb4c-29cb-4e7d-b690-081f5bab4b17
[INFO  2018-03-08 18:00:57][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 18:00:58][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 18:00:58][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:16)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 18:00:58][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 18:00:58][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 18:00:58][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 18:01:00][main] Logging$class:58 Successfully started service 'sparkDriver' on port 60161.
[INFO  2018-03-08 18:01:00][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 18:01:00][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 18:01:00][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:60176]
[INFO  2018-03-08 18:01:00][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 60176.
[INFO  2018-03-08 18:01:00][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 18:01:00][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 18:01:00][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-86e730bd-99b1-49d9-9aa7-8294c0b93fd6
[INFO  2018-03-08 18:01:00][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 18:01:01][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 18:01:01][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60188.
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Server created on 60188
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 18:01:01][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:60188 with 2.4 GB RAM, BlockManagerId(driver, localhost, 60188)
[INFO  2018-03-08 18:01:01][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 18:01:02][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:174
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Registering RDD 1 (sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:174) with 1 output partitions
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:174)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:159), which has no missing parents
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.4 KB, free 3.4 KB)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1987.0 B, free 5.3 KB)
[INFO  2018-03-08 18:01:02][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:60188 (size: 1987.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 18:01:02][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-08 18:01:02][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2105 bytes)
[INFO  2018-03-08 18:01:02][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 18:01:02][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 18:01:02][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:02][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 259 ms on localhost (1/2)
[INFO  2018-03-08 18:01:02][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:02][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 250 ms on localhost (2/2)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (sortBy at TransFomationOps.scala:159) finished in 0.289 s
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:159), which has no missing parents
[INFO  2018-03-08 18:01:02][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 8.8 KB)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 10.9 KB)
[INFO  2018-03-08 18:01:02][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:60188 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:02][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-08 18:01:02][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 18:01:02][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 6 ms
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 73 ms on localhost (1/1)
[INFO  2018-03-08 18:01:03][task-result-getter-2] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:174) finished in 0.072 s
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:174, took 0.729709 s
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Starting job: sortByKey at TransFomationOps.scala:181
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Got job 1 (sortByKey at TransFomationOps.scala:181) with 2 output partitions
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 2 (sortByKey at TransFomationOps.scala:181)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List()
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Missing parents: List()
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 2 (MapPartitionsRDD[6] at sortByKey at TransFomationOps.scala:181), which has no missing parents
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 2.4 KB, free 13.3 KB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1455.0 B, free 14.7 KB)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:60188 (size: 1455.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at sortByKey at TransFomationOps.scala:181)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Adding task set 2.0 with 2 tasks
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 2.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2121 bytes)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 2.0 (TID 4, localhost, partition 1,PROCESS_LOCAL, 2116 bytes)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 2.0 (TID 3)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 2.0 (TID 4)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 4). 1169 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 4) in 21 ms on localhost (1/2)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 3). 1169 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 3) in 28 ms on localhost (2/2)
[INFO  2018-03-08 18:01:03][task-result-getter-0] Logging$class:58 Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 ResultStage 2 (sortByKey at TransFomationOps.scala:181) finished in 0.030 s
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Job 1 finished: sortByKey at TransFomationOps.scala:181, took 0.047493 s
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:182
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Registering RDD 4 (map at TransFomationOps.scala:177)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Got job 2 (foreach at TransFomationOps.scala:182) with 2 output partitions
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 4 (foreach at TransFomationOps.scala:182)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 3)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 3)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:177), which has no missing parents
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_3 stored as values in memory (estimated size 2.9 KB, free 17.6 KB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_3_piece0 stored as bytes in memory (estimated size 1782.0 B, free 19.4 KB)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-0] Logging$class:58 Added broadcast_3_piece0 in memory on localhost:60188 (size: 1782.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Created broadcast 3 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[4] at map at TransFomationOps.scala:177)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Adding task set 3.0 with 2 tasks
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 3.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 3.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2105 bytes)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 3.0 (TID 6)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 3.0 (TID 5)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 6). 1159 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-1] Logging$class:58 Finished task 1.0 in stage 3.0 (TID 6) in 62 ms on localhost (1/2)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 5). 1159 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 5) in 66 ms on localhost (2/2)
[INFO  2018-03-08 18:01:03][task-result-getter-2] Logging$class:58 Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 3 (map at TransFomationOps.scala:177) finished in 0.069 s
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 4)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 4 (ShuffledRDD[7] at sortByKey at TransFomationOps.scala:181), which has no missing parents
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_4 stored as values in memory (estimated size 2.7 KB, free 22.1 KB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Block broadcast_4_piece0 stored as bytes in memory (estimated size 1673.0 B, free 23.7 KB)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-1] Logging$class:58 Added broadcast_4_piece0 in memory on localhost:60188 (size: 1673.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Created broadcast 4 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ResultStage 4 (ShuffledRDD[7] at sortByKey at TransFomationOps.scala:181)
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 Adding task set 4.0 with 2 tasks
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 4.0 (TID 7, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-3] Logging$class:58 Starting task 1.0 in stage 4.0 (TID 8, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 4.0 (TID 7)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 4.0 (TID 8)
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-08 18:01:03][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 4.0 (TID 8). 1165 bytes result sent to driver
[INFO  2018-03-08 18:01:03][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 4.0 (TID 7). 1165 bytes result sent to driver
[INFO  2018-03-08 18:01:03][task-result-getter-3] Logging$class:58 Finished task 1.0 in stage 4.0 (TID 8) in 22 ms on localhost (1/2)
[INFO  2018-03-08 18:01:03][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 4.0 (TID 7) in 25 ms on localhost (2/2)
[INFO  2018-03-08 18:01:03][task-result-getter-0] Logging$class:58 Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:03][dag-scheduler-event-loop] Logging$class:58 ResultStage 4 (foreach at TransFomationOps.scala:182) finished in 0.026 s
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Job 2 finished: foreach at TransFomationOps.scala:182, took 0.127651 s
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 18:01:03][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-0] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 18:01:03][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 18:01:03][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 18:01:03][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 18:01:03][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 18:01:03][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 18:01:03][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 18:01:03][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 18:01:03][sparkDriverActorSystem-akka.actor.default-dispatcher-6] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting shut down.
[INFO  2018-03-08 18:01:03][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 18:01:03][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-a2a46de1-ab03-4969-8168-86459f158325
[INFO  2018-03-08 18:01:46][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-08 18:01:47][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-08 18:01:48][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at com.bigdata.TransFormation.TransFomationOps$.main(TransFomationOps.scala:16)
	at com.bigdata.TransFormation.TransFomationOps.main(TransFomationOps.scala)
[INFO  2018-03-08 18:01:48][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-08 18:01:48][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-08 18:01:48][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-08 18:01:49][main] Logging$class:58 Successfully started service 'sparkDriver' on port 60691.
[INFO  2018-03-08 18:01:50][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-08 18:01:50][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-08 18:01:50][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:60704]
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 60704.
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-64d50ac9-b1bf-4235-9b0f-0effb7539300
[INFO  2018-03-08 18:01:50][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-08 18:01:50][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-08 18:01:50][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-08 18:01:50][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60717.
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Server created on 60717
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-08 18:01:51][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:60717 with 2.4 GB RAM, BlockManagerId(driver, localhost, 60717)
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-08 18:01:51][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:174
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Registering RDD 1 (sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at TransFomationOps.scala:174) with 1 output partitions
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at TransFomationOps.scala:174)
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-08 18:01:51][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:159), which has no missing parents
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 3.4 KB, free 3.4 KB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 1987.0 B, free 5.3 KB)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:60717 (size: 1987.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Created broadcast 0 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[1] at sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 2 tasks
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-1] Logging$class:58 Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2105 bytes)
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 0.0 (TID 1)
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:52][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 0.0 (TID 1) in 157 ms on localhost (1/2)
[INFO  2018-03-08 18:01:52][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on localhost (2/2)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (sortBy at TransFomationOps.scala:159) finished in 0.213 s
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:159), which has no missing parents
[INFO  2018-03-08 18:01:52][task-result-getter-1] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 8.8 KB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.0 KB, free 10.9 KB)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-3] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:60717 (size: 2.0 KB, free: 2.4 GB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at sortBy at TransFomationOps.scala:159)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 2)
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 9 ms
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-08 18:01:52][task-result-getter-2] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/1)
[INFO  2018-03-08 18:01:52][task-result-getter-2] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at TransFomationOps.scala:174) finished in 0.069 s
[INFO  2018-03-08 18:01:52][main] Logging$class:58 Job 0 finished: foreach at TransFomationOps.scala:174, took 0.655814 s
[INFO  2018-03-08 18:01:52][main] Logging$class:58 Starting job: foreach at TransFomationOps.scala:182
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Registering RDD 4 (map at TransFomationOps.scala:177)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Got job 1 (foreach at TransFomationOps.scala:182) with 1 output partitions
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 3 (foreach at TransFomationOps.scala:182)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 2)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 2)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 2 (MapPartitionsRDD[4] at map at TransFomationOps.scala:177), which has no missing parents
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.0 KB, free 13.9 KB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1798.0 B, free 15.6 KB)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-3] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:60717 (size: 1798.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[4] at map at TransFomationOps.scala:177)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Adding task set 2.0 with 2 tasks
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 2.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-2] Logging$class:58 Starting task 1.0 in stage 2.0 (TID 4, localhost, partition 1,PROCESS_LOCAL, 2105 bytes)
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Running task 1.0 in stage 2.0 (TID 4)
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 2.0 (TID 3)
[INFO  2018-03-08 18:01:52][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 3). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 4). 1158 bytes result sent to driver
[INFO  2018-03-08 18:01:52][task-result-getter-3] Logging$class:58 Finished task 0.0 in stage 2.0 (TID 3) in 71 ms on localhost (1/2)
[INFO  2018-03-08 18:01:52][task-result-getter-0] Logging$class:58 Finished task 1.0 in stage 2.0 (TID 4) in 74 ms on localhost (2/2)
[INFO  2018-03-08 18:01:52][task-result-getter-0] Logging$class:58 Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 2 (map at TransFomationOps.scala:177) finished in 0.078 s
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 3)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 3 (ShuffledRDD[5] at sortByKey at TransFomationOps.scala:181), which has no missing parents
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_3 stored as values in memory (estimated size 2.8 KB, free 18.4 KB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Block broadcast_3_piece0 stored as bytes in memory (estimated size 1690.0 B, free 20.0 KB)
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-0] Logging$class:58 Added broadcast_3_piece0 in memory on localhost:60717 (size: 1690.0 B, free: 2.4 GB)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Created broadcast 3 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 3 (ShuffledRDD[5] at sortByKey at TransFomationOps.scala:181)
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 Adding task set 3.0 with 1 tasks
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 3.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Running task 0.0 in stage 3.0 (TID 5)
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Getting 2 non-empty blocks out of 2 blocks
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-08 18:01:52][Executor task launch worker-1] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-08 18:01:52][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 3.0 (TID 5) in 16 ms on localhost (1/1)
[INFO  2018-03-08 18:01:52][task-result-getter-1] Logging$class:58 Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO  2018-03-08 18:01:52][dag-scheduler-event-loop] Logging$class:58 ResultStage 3 (foreach at TransFomationOps.scala:182) finished in 0.017 s
[INFO  2018-03-08 18:01:52][main] Logging$class:58 Job 1 finished: foreach at TransFomationOps.scala:182, took 0.132125 s
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-08 18:01:52][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-08 18:01:52][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-08 18:01:52][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-08 18:01:52][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-08 18:01:52][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-08 18:01:53][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-08 18:01:53][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-08 18:01:53][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-08 18:01:53][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-08 18:01:53][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-08 18:01:53][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-08 18:01:53][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-8c01b7ad-3237-4b28-8152-472b87cd05a4
