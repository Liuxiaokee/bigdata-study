[INFO  2018-03-05 10:01:11][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 10:01:12][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 10:01:12][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 10:01:12][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 10:01:12][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 10:01:12][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 10:01:14][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55700.
[INFO  2018-03-05 10:01:14][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 10:01:14][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 10:01:15][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55713]
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55713.
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-4a422128-64b7-43b8-999a-bb02a5a509b6
[INFO  2018-03-05 10:01:15][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 10:01:15][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 10:01:15][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55730.
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Server created on 55730
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 10:01:15][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:55730 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55730)
[INFO  2018-03-05 10:01:15][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 10:01:16][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 131.1 KB, free 131.1 KB)
[INFO  2018-03-05 10:01:16][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.4 KB, free 145.5 KB)
[INFO  2018-03-05 10:01:16][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:55730 (size: 14.4 KB, free: 2.4 GB)
[INFO  2018-03-05 10:01:16][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:19
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 10:01:20][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 10:01:20][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 10:01:20][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 10:01:20][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-9035fbdf-1f54-49b8-bb4c-e8eb07fc074d
[INFO  2018-03-05 10:01:20][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 10:01:20][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 10:02:23][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 10:02:24][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 10:02:25][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 10:02:25][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 10:02:25][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 10:02:25][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 10:02:26][main] Logging$class:58 Successfully started service 'sparkDriver' on port 56645.
[INFO  2018-03-05 10:02:26][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 10:02:27][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 10:02:27][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:56658]
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 56658.
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-6e7e6c56-dbf8-401d-847c-f6afa01f3ce9
[INFO  2018-03-05 10:02:27][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 10:02:27][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 10:02:27][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56666.
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Server created on 56666
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 10:02:27][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:56666 with 2.4 GB RAM, BlockManagerId(driver, localhost, 56666)
[INFO  2018-03-05 10:02:27][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 10:02:28][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 10:02:28][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 10:02:28][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:56666 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 10:02:28][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:19
[INFO  2018-03-05 10:02:29][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 10:02:29][main] Logging$class:58 Starting job: take at Top7OpsOfJava.java:34
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at Top7OpsOfJava.java:34) with 1 output partitions
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at Top7OpsOfJava.java:34)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21), which has no missing parents
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 10:02:29][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:56666 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 10:02:29][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 10:02:29][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[ERROR 2018-03-05 10:02:29][Executor task launch worker-0] Logging$class:95 Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "class1 90"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.valueOf(Integer.java:766)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:23)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:21)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[WARN  2018-03-05 10:02:29][task-result-getter-0] Logging$class:70 Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.NumberFormatException: For input string: "class1 90"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.valueOf(Integer.java:766)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:23)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:21)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[ERROR 2018-03-05 10:02:29][task-result-getter-0] Logging$class:74 Task 0 in stage 0.0 failed 1 times; aborting job
[INFO  2018-03-05 10:02:29][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 Cancelling stage 0
[INFO  2018-03-05 10:02:29][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at Top7OpsOfJava.java:21) failed in 0.346 s
[INFO  2018-03-05 10:02:29][main] Logging$class:58 Job 0 failed: take at Top7OpsOfJava.java:34, took 0.435163 s
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 10:02:29][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 10:02:29][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 10:02:29][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 10:02:29][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-6a9faa8e-8429-4a59-9b73-0827d6f8e401
[INFO  2018-03-05 10:02:29][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 10:02:29][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 10:04:01][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 10:04:03][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 10:04:03][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 10:04:03][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 10:04:03][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 10:04:03][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Successfully started service 'sparkDriver' on port 57584.
[INFO  2018-03-05 10:04:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 10:04:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 10:04:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:57637]
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 57637.
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-ba4cd300-ec72-4c77-86ee-fcd79ceb0c5b
[INFO  2018-03-05 10:04:05][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 10:04:05][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 10:04:06][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 10:04:06][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57655.
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Server created on 57655
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 10:04:06][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:57655 with 2.4 GB RAM, BlockManagerId(driver, localhost, 57655)
[INFO  2018-03-05 10:04:06][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 10:04:07][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 10:04:07][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 10:04:07][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:57655 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 10:04:07][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:19
[INFO  2018-03-05 10:04:07][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 10:04:07][main] Logging$class:58 Starting job: take at Top7OpsOfJava.java:34
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at Top7OpsOfJava.java:34) with 1 output partitions
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at Top7OpsOfJava.java:34)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21), which has no missing parents
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 10:04:07][dispatcher-event-loop-0] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:57655 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 10:04:07][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 10:04:07][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[ERROR 2018-03-05 10:04:07][Executor task launch worker-0] Logging$class:95 Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ArrayIndexOutOfBoundsException: 1
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:23)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:21)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[WARN  2018-03-05 10:04:07][task-result-getter-0] Logging$class:70 Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.ArrayIndexOutOfBoundsException: 1
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:23)
	at com.bigdata.sort.Top7OpsOfJava$1.call(Top7OpsOfJava.java:21)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[ERROR 2018-03-05 10:04:07][task-result-getter-0] Logging$class:74 Task 0 in stage 0.0 failed 1 times; aborting job
[INFO  2018-03-05 10:04:07][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 Cancelling stage 0
[INFO  2018-03-05 10:04:07][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at Top7OpsOfJava.java:21) failed in 0.165 s
[INFO  2018-03-05 10:04:07][main] Logging$class:58 Job 0 failed: take at Top7OpsOfJava.java:34, took 0.239954 s
[INFO  2018-03-05 10:04:07][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 10:04:07][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 10:04:08][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 10:04:08][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 10:04:08][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 10:04:08][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-06fb3045-a15e-41c5-abe0-e2f776eec317
[INFO  2018-03-05 10:04:08][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 10:05:37][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 10:05:38][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 10:05:39][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 10:05:39][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 10:05:39][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 10:05:39][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 10:05:40][main] Logging$class:58 Successfully started service 'sparkDriver' on port 58811.
[INFO  2018-03-05 10:05:41][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 10:05:41][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 10:05:41][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:58834]
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 58834.
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-051988ea-63a6-4b3b-9ad0-eec7b0b1d203
[INFO  2018-03-05 10:05:41][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 10:05:41][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 10:05:41][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58841.
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Server created on 58841
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 10:05:41][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:58841 with 2.4 GB RAM, BlockManagerId(driver, localhost, 58841)
[INFO  2018-03-05 10:05:41][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 10:05:42][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 10:05:42][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 10:05:42][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:58841 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 10:05:42][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:19
[INFO  2018-03-05 10:05:43][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 10:05:43][main] Logging$class:58 Starting job: take at Top7OpsOfJava.java:34
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at Top7OpsOfJava.java:34) with 1 output partitions
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at Top7OpsOfJava.java:34)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21), which has no missing parents
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 10:05:43][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:58841 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:21)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 10:05:43][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 10:05:43][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on localhost (1/1)
[INFO  2018-03-05 10:05:43][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at Top7OpsOfJava.java:21) finished in 0.206 s
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at map at Top7OpsOfJava.java:29), which has no missing parents
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 153.4 KB)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 155.6 KB)
[INFO  2018-03-05 10:05:43][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:58841 (size: 2.2 KB, free: 2.4 GB)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at Top7OpsOfJava.java:29)
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 10:05:43][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-05 10:05:43][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1297 bytes result sent to driver
[INFO  2018-03-05 10:05:43][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 137 ms on localhost (1/1)
[INFO  2018-03-05 10:05:43][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 10:05:43][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (take at Top7OpsOfJava.java:34) finished in 0.141 s
[INFO  2018-03-05 10:05:43][main] Logging$class:58 Job 0 finished: take at Top7OpsOfJava.java:34, took 0.461908 s
[INFO  2018-03-05 10:05:43][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 10:05:43][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 10:05:43][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 10:05:43][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 10:05:44][dispatcher-event-loop-1] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 10:05:44][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-8fe0564c-c5c2-4eaa-903c-051862e7b186
[INFO  2018-03-05 10:05:44][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 10:05:44][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 13:35:35][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 13:35:36][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 13:35:36][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.hadoop.JavaTop7Ops.main(JavaTop7Ops.java:16)
[INFO  2018-03-05 13:35:36][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 13:35:36][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 13:35:36][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 13:35:38][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54886.
[INFO  2018-03-05 13:35:39][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 13:35:39][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 13:35:39][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54903]
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54903.
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-4cd82e19-1af7-4b02-945b-1edb4ef52d3e
[INFO  2018-03-05 13:35:39][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 13:35:39][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 13:35:39][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 13:35:39][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 13:35:40][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 13:35:40][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54918.
[INFO  2018-03-05 13:35:40][main] Logging$class:58 Server created on 54918
[INFO  2018-03-05 13:35:40][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 13:35:40][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:54918 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54918)
[INFO  2018-03-05 13:35:40][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 13:35:41][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 13:35:41][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54918 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 13:35:41][main] Logging$class:58 Created broadcast 0 from textFile at JavaTop7Ops.java:19
[INFO  2018-03-05 13:35:41][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 13:35:41][main] Logging$class:58 Starting job: take at JavaTop7Ops.java:28
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at JavaTop7Ops.java:21)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at JavaTop7Ops.java:28) with 1 output partitions
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at JavaTop7Ops.java:28)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at JavaTop7Ops.java:21), which has no missing parents
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:54918 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at JavaTop7Ops.java:21)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 13:35:41][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 185 ms on localhost (1/1)
[INFO  2018-03-05 13:35:41][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at JavaTop7Ops.java:21) finished in 0.200 s
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at sortByKey at JavaTop7Ops.java:27), which has no missing parents
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 152.8 KB)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1928.0 B, free 154.7 KB)
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:54918 (size: 1928.0 B, free: 2.4 GB)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[3] at sortByKey at JavaTop7Ops.java:27)
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 5 ms
[INFO  2018-03-05 13:35:41][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1460 bytes result sent to driver
[INFO  2018-03-05 13:35:41][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 93 ms on localhost (1/1)
[INFO  2018-03-05 13:35:41][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 13:35:41][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (take at JavaTop7Ops.java:28) finished in 0.095 s
[INFO  2018-03-05 13:35:41][main] Logging$class:58 Job 0 finished: take at JavaTop7Ops.java:28, took 0.401511 s
[INFO  2018-03-05 13:35:41][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 13:35:41][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 13:35:41][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 13:35:41][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 13:35:41][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 13:35:41][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 13:35:41][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 13:35:42][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 13:35:42][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 13:35:42][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 13:35:42][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 13:35:42][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-86a346d4-b518-4c90-b98d-61a00b98d34a
[INFO  2018-03-05 13:37:25][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 13:37:27][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 13:37:27][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 13:37:27][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 13:37:27][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 13:37:27][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Successfully started service 'sparkDriver' on port 55519.
[INFO  2018-03-05 13:37:29][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 13:37:29][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 13:37:29][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:55540]
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 55540.
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-d94a45d1-5db1-4a0a-a8cd-227a0fd85c83
[INFO  2018-03-05 13:37:29][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 13:37:29][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 13:37:30][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 13:37:30][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55548.
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Server created on 55548
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 13:37:30][dispatcher-event-loop-1] Logging$class:58 Registering block manager localhost:55548 with 2.4 GB RAM, BlockManagerId(driver, localhost, 55548)
[INFO  2018-03-05 13:37:30][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 13:37:31][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 13:37:31][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 13:37:31][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:55548 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 13:37:31][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:20
[INFO  2018-03-05 13:37:31][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 13:37:31][main] Logging$class:58 Starting job: take at Top7OpsOfJava.java:30
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at Top7OpsOfJava.java:22)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at Top7OpsOfJava.java:30) with 1 output partitions
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at Top7OpsOfJava.java:30)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:22), which has no missing parents
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 13:37:31][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:55548 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:22)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 13:37:31][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 13:37:31][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 13:37:31][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 172 ms on localhost (1/1)
[INFO  2018-03-05 13:37:31][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at Top7OpsOfJava.java:22) finished in 0.189 s
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at sortByKey at Top7OpsOfJava.java:28), which has no missing parents
[INFO  2018-03-05 13:37:31][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 152.8 KB)
[INFO  2018-03-05 13:37:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1928.0 B, free 154.7 KB)
[INFO  2018-03-05 13:37:32][dispatcher-event-loop-2] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:55548 (size: 1928.0 B, free: 2.4 GB)
[INFO  2018-03-05 13:37:32][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 13:37:32][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[3] at sortByKey at Top7OpsOfJava.java:28)
[INFO  2018-03-05 13:37:32][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 13:37:32][dispatcher-event-loop-1] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 13:37:32][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 13:37:32][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 13:37:32][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-05 13:37:32][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1460 bytes result sent to driver
[INFO  2018-03-05 13:37:32][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (take at Top7OpsOfJava.java:30) finished in 0.065 s
[INFO  2018-03-05 13:37:32][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 63 ms on localhost (1/1)
[INFO  2018-03-05 13:37:32][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 13:37:32][main] Logging$class:58 Job 0 finished: take at Top7OpsOfJava.java:30, took 0.372489 s
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 13:37:32][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 13:37:32][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 13:37:32][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 13:37:32][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 13:37:32][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 13:37:32][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-9da1da44-1cc3-453c-b449-3a61634f26f9
[INFO  2018-03-05 16:02:15][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:02:16][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:02:16][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[ERROR 2018-03-05 16:02:16][main] Logging$class:95 Error initializing SparkContext.
org.apache.spark.SparkException: An application name must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:404)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:02:16][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:04:35][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:04:36][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:04:36][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:15)
[ERROR 2018-03-05 16:04:36][main] Logging$class:95 Error initializing SparkContext.
org.apache.spark.SparkException: An application name must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:404)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:15)
[INFO  2018-03-05 16:04:36][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:04:57][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:04:59][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:05:00][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:15)
[INFO  2018-03-05 16:05:00][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:05:00][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:05:00][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:05:01][main] Logging$class:58 Successfully started service 'sparkDriver' on port 57748.
[INFO  2018-03-05 16:05:02][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:05:02][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:05:02][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:57761]
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 57761.
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-d0be8d14-1876-4696-99c1-f27cea2a482b
[INFO  2018-03-05 16:05:02][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:05:02][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:05:02][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:05:02][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57768.
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Server created on 57768
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:05:03][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:57768 with 2.4 GB RAM, BlockManagerId(driver, localhost, 57768)
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:05:03][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:05:04][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:57768 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:05:04][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:16
[INFO  2018-03-05 16:05:04][main] Logging$class:58 Starting job: foreach at SecondrySort.java:25
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:18)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:25) with 7 output partitions
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:25)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:18), which has no missing parents
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 147.1 KB)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.8 KB)
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:57768 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:18)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2259 bytes result sent to driver
[INFO  2018-03-05 16:05:04][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 177 ms on localhost (1/1)
[INFO  2018-03-05 16:05:04][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:18) finished in 0.198 s
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at groupByKey at SecondrySort.java:24), which has no missing parents
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 6.1 KB, free 155.9 KB)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 159.1 KB)
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:57768 (size: 3.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Submitting 7 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at groupByKey at SecondrySort.java:24)
[INFO  2018-03-05 16:05:04][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 7 tasks
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 5 ms
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 2, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 2)
[INFO  2018-03-05 16:05:04][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 68 ms on localhost (1/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-2] Logging$class:58 Starting task 2.0 in stage 1.0 (TID 3, localhost, partition 2,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 2) in 44 ms on localhost (2/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 2.0 in stage 1.0 (TID 3)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 2.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-0] Logging$class:58 Starting task 3.0 in stage 1.0 (TID 4, localhost, partition 3,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 3.0 in stage 1.0 (TID 4)
[INFO  2018-03-05 16:05:04][task-result-getter-3] Logging$class:58 Finished task 2.0 in stage 1.0 (TID 3) in 26 ms on localhost (3/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 3.0 in stage 1.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-2] Logging$class:58 Starting task 4.0 in stage 1.0 (TID 5, localhost, partition 4,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 4.0 in stage 1.0 (TID 5)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:05:04][task-result-getter-0] Logging$class:58 Finished task 3.0 in stage 1.0 (TID 4) in 29 ms on localhost (4/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 4.0 in stage 1.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-0] Logging$class:58 Starting task 5.0 in stage 1.0 (TID 6, localhost, partition 5,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 5.0 in stage 1.0 (TID 6)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:05:04][task-result-getter-1] Logging$class:58 Finished task 4.0 in stage 1.0 (TID 5) in 35 ms on localhost (5/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Finished task 5.0 in stage 1.0 (TID 6). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:04][dispatcher-event-loop-2] Logging$class:58 Starting task 6.0 in stage 1.0 (TID 7, localhost, partition 6,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:05:04][task-result-getter-2] Logging$class:58 Finished task 5.0 in stage 1.0 (TID 6) in 18 ms on localhost (6/7)
[INFO  2018-03-05 16:05:04][Executor task launch worker-0] Logging$class:58 Running task 6.0 in stage 1.0 (TID 7)
[INFO  2018-03-05 16:05:05][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:05:05][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:05:05][Executor task launch worker-0] Logging$class:58 Finished task 6.0 in stage 1.0 (TID 7). 1165 bytes result sent to driver
[INFO  2018-03-05 16:05:05][task-result-getter-3] Logging$class:58 Finished task 6.0 in stage 1.0 (TID 7) in 16 ms on localhost (7/7)
[INFO  2018-03-05 16:05:05][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:05:05][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at SecondrySort.java:25) finished in 0.196 s
[INFO  2018-03-05 16:05:05][main] Logging$class:58 Job 0 finished: foreach at SecondrySort.java:25, took 0.759935 s
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:05:05][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:05:05][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:05:05][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:05:05][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-7cfd4d88-bb2e-4d57-a7fe-ca5e9e363df0
[INFO  2018-03-05 16:05:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:05:05][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:07:08][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:07:09][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:07:09][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:15)
[INFO  2018-03-05 16:07:10][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:07:10][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:07:10][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:07:10][main] Logging$class:58 Successfully started service 'sparkDriver' on port 58693.
[INFO  2018-03-05 16:07:11][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:07:11][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:07:11][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:58707]
[INFO  2018-03-05 16:07:11][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 58707.
[INFO  2018-03-05 16:07:11][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:07:11][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:07:11][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-efb68a0d-d661-4dc6-b766-033d0c4308a3
[INFO  2018-03-05 16:07:11][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:07:11][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:07:12][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:07:12][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58722.
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Server created on 58722
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:07:12][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:58722 with 2.4 GB RAM, BlockManagerId(driver, localhost, 58722)
[INFO  2018-03-05 16:07:12][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:07:13][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:07:13][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:07:13][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:58722 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:07:13][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:16
[INFO  2018-03-05 16:07:13][main] Logging$class:58 Starting job: foreach at SecondrySort.java:25
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:18)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:25) with 7 output partitions
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:25)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:18), which has no missing parents
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 5.0 KB, free 147.1 KB)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.8 KB)
[INFO  2018-03-05 16:07:13][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:58722 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:18)
[INFO  2018-03-05 16:07:13][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:07:13][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:07:13][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2259 bytes result sent to driver
[INFO  2018-03-05 16:07:14][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 224 ms on localhost (1/1)
[INFO  2018-03-05 16:07:14][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:18) finished in 0.240 s
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at groupByKey at SecondrySort.java:24), which has no missing parents
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 6.1 KB, free 155.9 KB)
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.1 KB, free 159.0 KB)
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:58722 (size: 3.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Submitting 7 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at groupByKey at SecondrySort.java:24)
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 7 tasks
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 3 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-0] Logging$class:58 Starting task 1.0 in stage 1.0 (TID 2, localhost, partition 1,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 61 ms on localhost (1/7)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 1.0 in stage 1.0 (TID 2)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 2). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-2] Logging$class:58 Starting task 2.0 in stage 1.0 (TID 3, localhost, partition 2,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 2.0 in stage 1.0 (TID 3)
[INFO  2018-03-05 16:07:14][task-result-getter-2] Logging$class:58 Finished task 1.0 in stage 1.0 (TID 2) in 26 ms on localhost (2/7)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 2.0 in stage 1.0 (TID 3). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-0] Logging$class:58 Starting task 3.0 in stage 1.0 (TID 4, localhost, partition 3,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][task-result-getter-3] Logging$class:58 Finished task 2.0 in stage 1.0 (TID 3) in 41 ms on localhost (3/7)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 3.0 in stage 1.0 (TID 4)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 3.0 in stage 1.0 (TID 4). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-2] Logging$class:58 Starting task 4.0 in stage 1.0 (TID 5, localhost, partition 4,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 4.0 in stage 1.0 (TID 5)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 4.0 in stage 1.0 (TID 5). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][task-result-getter-0] Logging$class:58 Finished task 3.0 in stage 1.0 (TID 4) in 39 ms on localhost (4/7)
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-0] Logging$class:58 Starting task 5.0 in stage 1.0 (TID 6, localhost, partition 5,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 5.0 in stage 1.0 (TID 6)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 1 ms
[INFO  2018-03-05 16:07:14][task-result-getter-1] Logging$class:58 Finished task 4.0 in stage 1.0 (TID 5) in 22 ms on localhost (5/7)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 5.0 in stage 1.0 (TID 6). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-2] Logging$class:58 Starting task 6.0 in stage 1.0 (TID 7, localhost, partition 6,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Running task 6.0 in stage 1.0 (TID 7)
[INFO  2018-03-05 16:07:14][task-result-getter-2] Logging$class:58 Finished task 5.0 in stage 1.0 (TID 6) in 19 ms on localhost (6/7)
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 0 ms
[INFO  2018-03-05 16:07:14][Executor task launch worker-0] Logging$class:58 Finished task 6.0 in stage 1.0 (TID 7). 1165 bytes result sent to driver
[INFO  2018-03-05 16:07:14][task-result-getter-3] Logging$class:58 Finished task 6.0 in stage 1.0 (TID 7) in 14 ms on localhost (7/7)
[INFO  2018-03-05 16:07:14][task-result-getter-3] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:07:14][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at SecondrySort.java:25) finished in 0.187 s
[INFO  2018-03-05 16:07:14][main] Logging$class:58 Job 0 finished: foreach at SecondrySort.java:25, took 0.735183 s
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:07:14][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:07:14][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:07:14][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:07:14][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:07:14][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-2f1d8ed4-d7d2-49c7-b58a-dfbd4931e982
[INFO  2018-03-05 16:19:33][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:19:35][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:19:35][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[ERROR 2018-03-05 16:19:35][main] Logging$class:95 Error initializing SparkContext.
org.apache.spark.SparkException: An application name must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:404)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:19:35][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:20:10][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:20:11][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:20:11][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:20:11][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:20:11][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:20:11][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:20:12][main] Logging$class:58 Successfully started service 'sparkDriver' on port 64910.
[INFO  2018-03-05 16:20:13][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:20:13][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:20:13][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:64923]
[INFO  2018-03-05 16:20:13][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 64923.
[INFO  2018-03-05 16:20:13][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:20:13][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:20:13][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-6feb8a46-118e-4850-b350-14938f76a885
[INFO  2018-03-05 16:20:13][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:20:14][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:20:14][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64930.
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Server created on 64930
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:20:14][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:64930 with 2.4 GB RAM, BlockManagerId(driver, localhost, 64930)
[INFO  2018-03-05 16:20:14][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:20:15][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:20:15][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:20:15][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:64930 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:20:15][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:18
[INFO  2018-03-05 16:20:15][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:20:15][main] Logging$class:58 Starting job: foreach at SecondrySort.java:37
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:37) with 1 output partitions
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:37)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20), which has no missing parents
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 16:20:15][dispatcher-event-loop-0] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:64930 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:20:15][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:20:15][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:20:15][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[ERROR 2018-03-05 16:20:16][Executor task launch worker-0] Logging$class:95 Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "class1"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.valueOf(Integer.java:766)
	at com.bigdata.sort.SecondrySort$1.call(SecondrySort.java:24)
	at com.bigdata.sort.SecondrySort$1.call(SecondrySort.java:20)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[WARN  2018-03-05 16:20:16][task-result-getter-0] Logging$class:70 Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.NumberFormatException: For input string: "class1"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.valueOf(Integer.java:766)
	at com.bigdata.sort.SecondrySort$1.call(SecondrySort.java:24)
	at com.bigdata.sort.SecondrySort$1.call(SecondrySort.java:20)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[ERROR 2018-03-05 16:20:16][task-result-getter-0] Logging$class:74 Task 0 in stage 0.0 failed 1 times; aborting job
[INFO  2018-03-05 16:20:16][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:20:16][dag-scheduler-event-loop] Logging$class:58 Cancelling stage 0
[INFO  2018-03-05 16:20:16][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:20) failed in 0.190 s
[INFO  2018-03-05 16:20:16][main] Logging$class:58 Job 0 failed: foreach at SecondrySort.java:37, took 0.289464 s
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 Invoking stop() from shutdown hook
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:20:16][Thread-2] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:20:16][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:20:16][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:20:16][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:20:16][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:20:16][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-72ae3d48-fab2-4f31-b9db-d9ee1219c163
[INFO  2018-03-05 16:22:11][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:22:12][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:22:13][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:22:13][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:22:13][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:22:13][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:22:14][main] Logging$class:58 Successfully started service 'sparkDriver' on port 49327.
[INFO  2018-03-05 16:22:15][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:22:15][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:22:15][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:49348]
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 49348.
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-a800e7df-1420-4f7b-8523-405e1b6e81d2
[INFO  2018-03-05 16:22:15][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:22:15][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:22:15][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:22:15][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:22:16][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:22:16][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49355.
[INFO  2018-03-05 16:22:16][main] Logging$class:58 Server created on 49355
[INFO  2018-03-05 16:22:16][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:22:16][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:49355 with 2.4 GB RAM, BlockManagerId(driver, localhost, 49355)
[INFO  2018-03-05 16:22:16][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:22:17][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:22:17][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:22:17][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:49355 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:22:17][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:18
[INFO  2018-03-05 16:22:17][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:22:17][main] Logging$class:58 Starting job: foreach at SecondrySort.java:37
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:37) with 1 output partitions
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:37)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20), which has no missing parents
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 16:22:17][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:49355 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:22:17][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/3.txt:0+101
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 16:22:17][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on localhost (1/1)
[INFO  2018-03-05 16:22:17][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:20) finished in 0.239 s
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31), which has no missing parents
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 153.4 KB)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 155.6 KB)
[INFO  2018-03-05 16:22:17][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:49355 (size: 2.2 KB, free: 2.4 GB)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31)
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 16:22:17][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 5 ms
[INFO  2018-03-05 16:22:17][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1165 bytes result sent to driver
[INFO  2018-03-05 16:22:17][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 95 ms on localhost (1/1)
[INFO  2018-03-05 16:22:17][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:22:17][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at SecondrySort.java:37) finished in 0.097 s
[INFO  2018-03-05 16:22:17][main] Logging$class:58 Job 0 finished: foreach at SecondrySort.java:37, took 0.470362 s
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:22:17][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:22:18][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:22:18][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:22:18][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:22:18][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:22:18][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:22:18][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:22:18][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:22:18][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:22:18][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:22:18][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:22:18][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-ba6abe42-5d04-4018-8bba-cf9875867e1f
[INFO  2018-03-05 16:33:00][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:33:01][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:33:02][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:33:02][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:33:02][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:33:02][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:33:04][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54415.
[INFO  2018-03-05 16:33:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:33:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:33:04][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54429]
[INFO  2018-03-05 16:33:04][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54429.
[INFO  2018-03-05 16:33:04][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:33:04][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:33:04][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-fbfcaa03-dd38-4fad-b922-cf78858a5f0d
[INFO  2018-03-05 16:33:04][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:33:05][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:33:05][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54453.
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Server created on 54453
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:33:05][dispatcher-event-loop-0] Logging$class:58 Registering block manager localhost:54453 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54453)
[INFO  2018-03-05 16:33:05][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:33:06][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:33:06][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:33:06][dispatcher-event-loop-3] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54453 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:06][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:18
[INFO  2018-03-05 16:33:07][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:33:07][main] Logging$class:58 Starting job: foreach at SecondrySort.java:37
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:37) with 1 output partitions
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:37)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20), which has no missing parents
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:54453 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/3.txt:0+101
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 16:33:07][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 204 ms on localhost (1/1)
[INFO  2018-03-05 16:33:07][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:20) finished in 0.223 s
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31), which has no missing parents
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 153.4 KB)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 155.6 KB)
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-2] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:54453 (size: 2.2 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31)
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-0] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-05 16:33:07][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1165 bytes result sent to driver
[INFO  2018-03-05 16:33:07][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 112 ms on localhost (1/1)
[INFO  2018-03-05 16:33:07][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:33:07][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at SecondrySort.java:37) finished in 0.116 s
[INFO  2018-03-05 16:33:07][main] Logging$class:58 Job 0 finished: foreach at SecondrySort.java:37, took 0.484588 s
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:33:07][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:33:07][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-1] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:33:07][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:33:07][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:33:07][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:33:07][dispatcher-event-loop-3] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:33:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:33:07][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:33:07][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:33:07][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:33:07][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-9663fbdc-d040-4a4d-a811-20aa8bbb1629
[INFO  2018-03-05 16:33:26][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:33:27][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:33:28][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.SecondrySort.main(SecondrySort.java:17)
[INFO  2018-03-05 16:33:28][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:33:28][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:33:28][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:33:29][main] Logging$class:58 Successfully started service 'sparkDriver' on port 54673.
[INFO  2018-03-05 16:33:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:33:30][sparkDriverActorSystem-akka.actor.default-dispatcher-3] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:33:30][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:54694]
[INFO  2018-03-05 16:33:30][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 54694.
[INFO  2018-03-05 16:33:30][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:33:30][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:33:30][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-cbe61068-180e-4720-917c-426a662aea4d
[INFO  2018-03-05 16:33:30][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:33:30][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:33:31][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:33:31][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54701.
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Server created on 54701
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:33:31][dispatcher-event-loop-2] Logging$class:58 Registering block manager localhost:54701 with 2.4 GB RAM, BlockManagerId(driver, localhost, 54701)
[INFO  2018-03-05 16:33:31][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:33:32][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:33:32][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:33:32][dispatcher-event-loop-0] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:54701 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:32][main] Logging$class:58 Created broadcast 0 from textFile at SecondrySort.java:18
[INFO  2018-03-05 16:33:32][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:33:32][main] Logging$class:58 Starting job: foreach at SecondrySort.java:37
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Got job 0 (foreach at SecondrySort.java:37) with 1 output partitions
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (foreach at SecondrySort.java:37)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20), which has no missing parents
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 16:33:32][dispatcher-event-loop-1] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:54701 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at SecondrySort.java:20)
[INFO  2018-03-05 16:33:32][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:33:32][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:33:32][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 16:33:33][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 179 ms on localhost (1/1)
[INFO  2018-03-05 16:33:33][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at SecondrySort.java:20) finished in 0.200 s
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31), which has no missing parents
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 153.4 KB)
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 155.6 KB)
[INFO  2018-03-05 16:33:33][dispatcher-event-loop-1] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:54701 (size: 2.2 KB, free: 2.4 GB)
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at SecondrySort.java:31)
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 16:33:33][dispatcher-event-loop-2] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-05 16:33:33][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1165 bytes result sent to driver
[INFO  2018-03-05 16:33:33][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 70 ms on localhost (1/1)
[INFO  2018-03-05 16:33:33][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:33:33][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (foreach at SecondrySort.java:37) finished in 0.072 s
[INFO  2018-03-05 16:33:33][main] Logging$class:58 Job 0 finished: foreach at SecondrySort.java:37, took 0.402871 s
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:33:33][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:33:33][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:33:33][dispatcher-event-loop-2] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:33:33][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:33:33][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:33:33][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:33:33][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:33:33][dispatcher-event-loop-0] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:33:33][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:33:33][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:33:33][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:33:33][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-571e8035-0c85-42b3-a314-f2554042db66
[INFO  2018-03-05 16:45:07][main] Logging$class:58 Running Spark version 1.6.2
[WARN  2018-03-05 16:45:08][main] NativeCodeLoader:62 Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR 2018-03-05 16:45:08][main] Shell:373 Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)
	at com.bigdata.sort.Top7OpsOfJava.main(Top7OpsOfJava.java:17)
[INFO  2018-03-05 16:45:08][main] Logging$class:58 Changing view acls to: GMW
[INFO  2018-03-05 16:45:08][main] Logging$class:58 Changing modify acls to: GMW
[INFO  2018-03-05 16:45:08][main] Logging$class:58 SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(GMW); users with modify permissions: Set(GMW)
[INFO  2018-03-05 16:45:09][main] Logging$class:58 Successfully started service 'sparkDriver' on port 60178.
[INFO  2018-03-05 16:45:10][sparkDriverActorSystem-akka.actor.default-dispatcher-5] Slf4jLogger$$anonfun$receive$1:80 Slf4jLogger started
[INFO  2018-03-05 16:45:10][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Starting remoting
[INFO  2018-03-05 16:45:10][sparkDriverActorSystem-akka.actor.default-dispatcher-4] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.68.44:60199]
[INFO  2018-03-05 16:45:10][main] Logging$class:58 Successfully started service 'sparkDriverActorSystem' on port 60199.
[INFO  2018-03-05 16:45:10][main] Logging$class:58 Registering MapOutputTracker
[INFO  2018-03-05 16:45:10][main] Logging$class:58 Registering BlockManagerMaster
[INFO  2018-03-05 16:45:10][main] Logging$class:58 Created local directory at C:\Users\GMW\AppData\Local\Temp\blockmgr-d2338d80-e5d7-4c86-8bb3-359d2bed03cd
[INFO  2018-03-05 16:45:10][main] Logging$class:58 MemoryStore started with capacity 2.4 GB
[INFO  2018-03-05 16:45:10][main] Logging$class:58 Registering OutputCommitCoordinator
[INFO  2018-03-05 16:45:11][main] Server:272 jetty-8.y.z-SNAPSHOT
[INFO  2018-03-05 16:45:11][main] AbstractConnector:338 Started SelectChannelConnector@0.0.0.0:4040
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Successfully started service 'SparkUI' on port 4040.
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Started SparkUI at http://192.168.68.44:4040
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Starting executor ID driver on host localhost
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60206.
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Server created on 60206
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Trying to register BlockManager
[INFO  2018-03-05 16:45:11][dispatcher-event-loop-3] Logging$class:58 Registering block manager localhost:60206 with 2.4 GB RAM, BlockManagerId(driver, localhost, 60206)
[INFO  2018-03-05 16:45:11][main] Logging$class:58 Registered BlockManager
[INFO  2018-03-05 16:45:12][main] Logging$class:58 Block broadcast_0 stored as values in memory (estimated size 128.0 KB, free 128.0 KB)
[INFO  2018-03-05 16:45:12][main] Logging$class:58 Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.1 KB, free 142.1 KB)
[INFO  2018-03-05 16:45:12][dispatcher-event-loop-1] Logging$class:58 Added broadcast_0_piece0 in memory on localhost:60206 (size: 14.1 KB, free: 2.4 GB)
[INFO  2018-03-05 16:45:12][main] Logging$class:58 Created broadcast 0 from textFile at Top7OpsOfJava.java:20
[INFO  2018-03-05 16:45:12][main] FileInputFormat:247 Total input paths to process : 1
[INFO  2018-03-05 16:45:12][main] Logging$class:58 Starting job: take at Top7OpsOfJava.java:30
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Registering RDD 2 (mapToPair at Top7OpsOfJava.java:22)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Got job 0 (take at Top7OpsOfJava.java:30) with 1 output partitions
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Final stage: ResultStage 1 (take at Top7OpsOfJava.java:30)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Parents of final stage: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Missing parents: List(ShuffleMapStage 0)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:22), which has no missing parents
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1 stored as values in memory (estimated size 4.8 KB, free 146.8 KB)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 149.6 KB)
[INFO  2018-03-05 16:45:12][dispatcher-event-loop-2] Logging$class:58 Added broadcast_1_piece0 in memory on localhost:60206 (size: 2.7 KB, free: 2.4 GB)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at mapToPair at Top7OpsOfJava.java:22)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Adding task set 0.0 with 1 tasks
[INFO  2018-03-05 16:45:12][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2110 bytes)
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 0.0 (TID 0)
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Logging$class:58 Input split: file:/F:/data/5.txt:0+174
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Configuration:1129 mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Configuration:1129 mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Configuration:1129 mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Configuration:1129 mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Configuration:1129 mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO  2018-03-05 16:45:12][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0). 2253 bytes result sent to driver
[INFO  2018-03-05 16:45:12][task-result-getter-0] Logging$class:58 Finished task 0.0 in stage 0.0 (TID 0) in 174 ms on localhost (1/1)
[INFO  2018-03-05 16:45:12][task-result-getter-0] Logging$class:58 Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 ShuffleMapStage 0 (mapToPair at Top7OpsOfJava.java:22) finished in 0.191 s
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 looking for newly runnable stages
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 running: Set()
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 waiting: Set(ResultStage 1)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 failed: Set()
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Submitting ResultStage 1 (ShuffledRDD[3] at sortByKey at Top7OpsOfJava.java:28), which has no missing parents
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 152.8 KB)
[INFO  2018-03-05 16:45:12][dag-scheduler-event-loop] Logging$class:58 Block broadcast_2_piece0 stored as bytes in memory (estimated size 1928.0 B, free 154.7 KB)
[INFO  2018-03-05 16:45:13][dispatcher-event-loop-2] Logging$class:58 Added broadcast_2_piece0 in memory on localhost:60206 (size: 1928.0 B, free: 2.4 GB)
[INFO  2018-03-05 16:45:13][dag-scheduler-event-loop] Logging$class:58 Created broadcast 2 from broadcast at DAGScheduler.scala:1006
[INFO  2018-03-05 16:45:13][dag-scheduler-event-loop] Logging$class:58 Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[3] at sortByKey at Top7OpsOfJava.java:28)
[INFO  2018-03-05 16:45:13][dag-scheduler-event-loop] Logging$class:58 Adding task set 1.0 with 1 tasks
[INFO  2018-03-05 16:45:13][dispatcher-event-loop-3] Logging$class:58 Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1894 bytes)
[INFO  2018-03-05 16:45:13][Executor task launch worker-0] Logging$class:58 Running task 0.0 in stage 1.0 (TID 1)
[INFO  2018-03-05 16:45:13][Executor task launch worker-0] Logging$class:58 Getting 1 non-empty blocks out of 1 blocks
[INFO  2018-03-05 16:45:13][Executor task launch worker-0] Logging$class:58 Started 0 remote fetches in 4 ms
[INFO  2018-03-05 16:45:13][Executor task launch worker-0] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1). 1460 bytes result sent to driver
[INFO  2018-03-05 16:45:13][task-result-getter-1] Logging$class:58 Finished task 0.0 in stage 1.0 (TID 1) in 65 ms on localhost (1/1)
[INFO  2018-03-05 16:45:13][task-result-getter-1] Logging$class:58 Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO  2018-03-05 16:45:13][dag-scheduler-event-loop] Logging$class:58 ResultStage 1 (take at Top7OpsOfJava.java:30) finished in 0.068 s
[INFO  2018-03-05 16:45:13][main] Logging$class:58 Job 0 finished: take at Top7OpsOfJava.java:30, took 0.376386 s
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/api,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/static,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/executors,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/environment,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/storage,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/stages,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
[INFO  2018-03-05 16:45:13][main] ContextHandler:843 stopped o.s.j.s.ServletContextHandler{/jobs,null}
[INFO  2018-03-05 16:45:13][main] Logging$class:58 Stopped Spark web UI at http://192.168.68.44:4040
[INFO  2018-03-05 16:45:13][dispatcher-event-loop-3] Logging$class:58 MapOutputTrackerMasterEndpoint stopped!
[INFO  2018-03-05 16:45:13][main] Logging$class:58 MemoryStore cleared
[INFO  2018-03-05 16:45:13][main] Logging$class:58 BlockManager stopped
[INFO  2018-03-05 16:45:13][main] Logging$class:58 BlockManagerMaster stopped
[INFO  2018-03-05 16:45:13][dispatcher-event-loop-2] Logging$class:58 OutputCommitCoordinator stopped!
[INFO  2018-03-05 16:45:13][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Shutting down remote daemon.
[INFO  2018-03-05 16:45:13][main] Logging$class:58 Successfully stopped SparkContext
[INFO  2018-03-05 16:45:13][sparkDriverActorSystem-akka.actor.default-dispatcher-2] Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3:74 Remote daemon shut down; proceeding with flushing remote transports.
[INFO  2018-03-05 16:45:13][Thread-2] Logging$class:58 Shutdown hook called
[INFO  2018-03-05 16:45:13][Thread-2] Logging$class:58 Deleting directory C:\Users\GMW\AppData\Local\Temp\spark-61bd4353-b63d-4982-8bbc-e2fc1f0abc0a
